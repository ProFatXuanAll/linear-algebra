\section{Linear Transformations, Null Spaces and Ranges}\label{sec:2.1}

\begin{defn}\label{2.1.1}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\).
  We call a function \(\T : \V \to \W\) a \textbf{linear transformation from \(\V\) to \(\W\)} if, for all \(x, y \in \V\) and \(c \in \F\), we have
  \begin{enumerate}
    \item \(\T(x + y) = \T(x) + \T(y)\) and
    \item \(\T(cx) = c\T(x)\).
  \end{enumerate}
  We often simply call \(\T\) \textbf{linear}.
\end{defn}

\begin{note}
  If the underlying field \(\F\) is the field of rational numbers, then \cref{2.1.1}(a) implies \cref{2.1.1}(b) (see \cref{ex:2.1.37}), but, in general \cref{2.1.1}(a)(b) are logically independent.
\end{note}

\begin{prop}\label{2.1.2}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\) and let \(\T : \V \to \W\) be a function.
  \begin{enumerate}
    \item If \(\T\) is linear, then \(\T(\zv_v) = \zv_w\).
    \item \(\T\) is linear if and only if \(\T(cx + y) = c\T(x) + \T(y)\) for all \(x, y \in \V\) and \(c \in \F\).
    \item If \(\T\) is linear, then \(\T(x - y) = \T(x) - \T(y)\) for all \(x, y \in \V\).
    \item \(\T\) is linear if and only if, for \(\seq{x}{1,2,,n} \in \V\) and \(\seq{a}{1,2,,n} \in F\), we have
          \[
            \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n a_i \T(x_i).
          \]
  \end{enumerate}
\end{prop}

\begin{proof}[\pf{2.1.2}(a)]
  We have
  \begin{align*}
             & \T \text{ is linear}                                                       \\
    \implies & \T(\zv_v) + \T(\zv_v) = \T(\zv_v + \zv_v) &  & \text{(by \cref{2.1.1}(a))} \\
             & = \T(\zv_v) = \T(\zv_v) + \zv_w           &  & \text{(by \ref{vs3})}       \\
    \implies & \T(\zv_v) = \zv_w.                        &  & \text{(by \cref{1.1})}
  \end{align*}
\end{proof}

\begin{proof}[\pf{2.1.2}(b)]
  We have
  \begin{align*}
             & \T \text{ is linear}                                                                                  \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \begin{dcases}
      \T(x + y) = \T(x) + \T(y) \\
      \T(cx) = c\T(x)
    \end{dcases}                    &  & \text{(by \cref{2.1.1})} \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \T(cx + y) = \T(cx) + \T(y) = c\T(x) + \T(y) &  & \text{(by \cref{2.1.1})}
  \end{align*}
  and
  \begin{align*}
             & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \T(cx + y) = c\T(x) + \T(y)                                  \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \begin{dcases}
      \T(x + y) = \T(x) + \T(y)       & \text{if } c = 0     \\
      \T(cx + \zv_v) = c\T(x) + \zv_w & \text{if } y = \zv_v
    \end{dcases}  &  & \text{(by \cref{2.1.2}(a))} \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \begin{dcases}
      \T(x + y) = \T(x) + \T(y) & \text{if } c = 0     \\
      \T(cx) = c\T(x)           & \text{if } y = \zv_v
    \end{dcases} &  & \text{(by \ref{vs3})}       \\
    \implies & \T \text{ is linear}.                                  &  & \text{(by \cref{2.1.1})}
  \end{align*}
  Thus
  \[
    \T \text{ is linear} \iff \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \T(cx + y) = c\T(x) + \T(y).
  \]
\end{proof}

\begin{proof}[\pf{2.1.2}(c)]
  For all \(x, y \in \V\), we have
  \begin{align*}
    \T(x - y) & = \T(x + (-1)y)      &  & \text{(by \cref{1.2}(b))}   \\
              & = \T(x) + \T((-1)y)  &  & \text{(by \cref{2.1.1}(a))} \\
              & = \T(x) + (-1) \T(y) &  & \text{(by \cref{2.1.1}(b))} \\
              & = \T(x) - \T(y).     &  & \text{(by \cref{1.2}(b))}
  \end{align*}
\end{proof}

\begin{proof}[\pf{2.1.2}(d)]
  We have
  \begin{align*}
             & \T \text{ is linear}                                                                                                  \\
    \implies & \begin{dcases}
      \forall \seq{x}{1,2,,n} \in \V \\
      \forall \seq{a}{1,2,,n} \in \F
    \end{dcases},                                                                                           \\
             & \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n \T(a_i x_i) = \sum_{i = 1}^n a_i \T(x_i) &  & \text{(by \cref{2.1.1})}
  \end{align*}
  and
  \begin{align*}
             & \begin{dcases}
      \forall \seq{x}{1,2,,n} \in \V \\
      \forall \seq{a}{1,2,,n} \in \F
    \end{dcases},                                                                 \\
             & \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n a_i \T(x_i) &  & \text{(by \cref{2.1.1})}    \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases},                                                                 \\
             & \T(cx + 1y) = c\T(x) + 1\T(y) = c\T(x) + \T(y)             &  & \text{(by \ref{vs5})}       \\
    \implies & \T \text{ is linear}.                                      &  & \text{(by \cref{2.1.2}(b))}
  \end{align*}
  Thus
  \[
    \T \text{ is linear} \iff \begin{dcases}
      \forall \seq{x}{1,2,,n} \in \V \\
      \forall \seq{a}{1,2,,n} \in \F
    \end{dcases}, \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n a_i \T(x_i).
  \]
\end{proof}

\begin{note}
  We generally use \cref{2.1.2}(b) to prove that a given transformation is linear.
\end{note}

\begin{eg}\label{2.1.3}
  For any angle \(\theta\), define \(\T_{\theta} : \R^2 \to \R^2\) by the rule: \(\T_{\theta}(a_1, a_2)\) is the vector obtained by rotating \((a_1, a_2)\) counterclockwise by \(\theta\) if \((a_1, a_2) \neq (0, 0)\), and \(\T_{\theta}(0, 0) = (0, 0)\).
  Then \(\T_{\theta} : \R^2 \to \R^2\) is a linear transformation that is called the \textbf{rotation by \(\theta\)}.

  We determine an explicit formula for \(\T_{\theta}\).
  Fix a nonzero vector \((a_1, a_2) \in \R^2\).
  Let \(\alpha\) be the angle that \((a_1, a_2)\) makes with the positive \(x\)-axis, and let \(r = \sqrt{a_1^2 +a_2^2}\).
  Then \(a_1 = r \cos(\alpha)\) and \(a_2 = r \sin(\alpha)\).
  Also, \(\T_{\theta}(a_1, a_2)\) has length \(r\) and makes an angle \(\alpha + \theta\) with the positive \(x\)-axis.
  It follows that
  \begin{align*}
    \T_{\theta}(a_1, a_2) & = (r \cos(\alpha + \theta), r \sin(\alpha + \theta))                                                                     \\
                          & = (r \cos(\alpha) \cos(\theta) - r \sin(\alpha) \sin(\theta), r \cos(\alpha) \sin(\theta) + r \sin(\alpha) \cos(\theta)) \\
                          & = (a_1 \cos(\theta) - a_2 \sin(\theta), a_1 \sin(\theta) + a_2 \cos(\theta)).
  \end{align*}
  Finally, observe that this same formula is valid for \((a_1 ,a_2) = (0, 0)\).
  It is now easy to show that \(\T_{\theta}\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.3}]
  For all \(x, y \in \R^2\) and \(c \in \R\), we have
  \begin{align*}
    \T_{\theta}(cx + y) & = \T_{\theta}(cx_1 + y_1, cx_2 + y_2)                                              &  & \text{(by \cref{1.2.4})} \\
                        & = ((cx_1 + y_1) \cos(\theta) - (cx_2 + y_2)\sin(\theta),                                                         \\
                        & \quad (cx_1 + y_1) \sin(\theta) + (cx_2 + y_2) \cos(\theta))                       &  & \text{(by \cref{2.1.3})} \\
                        & = c (x_1 \cos(\theta) - x_2 \sin(\theta), x_1 \sin(\theta) + x_2 \cos(\theta))     &  & \text{(by \cref{1.2.1})} \\
                        & \quad + (y_1 \cos(\theta) - y_2 \sin(\theta), y_1 \sin(\theta) + y_2 \cos(\theta))                               \\
                        & = c\T(x_1, x_2) + \T(y_1, y_2)                                                     &  & \text{(by \cref{2.1.3})} \\
                        & = c\T_{\theta}(x) + \T_{\theta}(y).                                                &  & \text{(by \cref{1.2.4})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\T_{\theta}\) is linear.
\end{proof}

\begin{eg}\label{2.1.4}
  Define \(\T : \R^2 \to \R^2\) by \(\T(a_1, a_2) = (a_1, -a_2)\).
  \(\T\) is called the \textbf{reflection about the \(x\)-axis} and \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.4}]
  For all \(x, y \in \R^2\) and \(c \in \R\), we have
  \begin{align*}
    \T(cx + y) & = \T(cx_1 + y_1, cx_2 + y_2)   &  & \text{(by \cref{1.2.4})} \\
               & = (cx_1 + y_1, -cx_2 - y_2)    &  & \text{(by \cref{2.1.4})} \\
               & = c(x_1, -x_2) + (y_1, -y_2)   &  & \text{(by \cref{1.2.1})} \\
               & = c\T(x_1, x_2) + \T(y_1, y_2) &  & \text{(by \cref{2.1.4})} \\
               & = c\T(x) + \T(y).              &  & \text{(by \cref{1.2.4})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.5}
  Define \(\T : \R^2 \to \R^2\) by \(\T(a_1, a_2) = (a_1, 0)\).
  \(\T\) is called the \textbf{projection on the \(x\)-axis} and \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.5}]
  For all \(x, y \in \R^2\) and \(c \in \R\), we have
  \begin{align*}
    \T(cx + y) & = \T(cx_1 + y_1, cx_2 + y_2)   &  & \text{(by \cref{1.2.4})} \\
               & = (cx_1 + y_1, 0)              &  & \text{(by \cref{2.1.5})} \\
               & = c(x_1, 0) + (y_1, 0)         &  & \text{(by \cref{1.2.1})} \\
               & = c\T(x_1, x_2) + \T(y_1, y_2) &  & \text{(by \cref{2.1.5})} \\
               & = c\T(x) + \T(y).              &  & \text{(by \cref{1.2.4})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.6}
  Define \(\T : \ms{m}{n}{\F} \to \ms{n}{m}{\F}\) by \(\T(A) = \tp{A}\), where \(\tp{A}\) is the transpose of \(A\), defined in \cref{1.3.3}.
  Then \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.6}]
  By \cref{ex:1.3.3} and \cref{2.1.2}(b) we see that \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.7}
  Define \(\T : \ps[n]{\R} \to \ps[n - 1]{\R}\) by \(\T(f(x)) = f'(x)\), where \(f'(x)\) denotes the derivative of \(f(x)\).
  Then \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.7}]
  Let \(g(x), h(x) \in \ps[n]{\R}\) and \(a \in \R\).
  Now
  \[
    \T(ag(x) + h(x)) = (ag(x) + h(x))' = ag'(x) + h'(x) = a\T(g(x)) + \T(h(x)).
  \]
  So by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.8}
  Let \(\V = \cfs{\R}\), the vector space of continuous real-valued functions on \(\R\).
  Let \(a, b \in \R\), \(a < b\).
  Define \(\T : \V \to \R\) by
  \[
    \T(f) = \int_a^b f(t) \; dt
  \]
  for all \(f \in \V\).
  Then \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.8}]
  Let \(g, h \in \cfs{\R}\) and \(a \in \R\).
  Now
  \begin{align*}
    \T(cg + h) & = \int_a^b (cg + h)(t) \; dt                  &  & \text{(by \cref{2.1.8})}  \\
               & = \int_a^b cg(t) + h(t) \; dt                 &  & \text{(by \cref{1.2.10})} \\
               & = c \int_a^b g(t) \; dt + \int_a^b h(t) \; dt                                \\
               & = c \T(g) + \T(h).                            &  & \text{(by \cref{2.1.8})}
  \end{align*}
  So by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\exercisesection

\begin{ex}\label{ex:2.1.37}
  A function \(\T : \V \to \W\) between vector spaces \(\V\) and \(\W\) over \(\F\) is called \textbf{additive} if \(\T(x + y) = \T(x) + \T(y)\) for all \(x, y \in \V\).
  Prove that if \(\V\) and \(\W\) are vector spaces over the field of rational numbers \(\Q\), then any additive function from \(\V\) into \(\W\) is a linear transformation.
\end{ex}
