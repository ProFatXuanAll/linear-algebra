\section{Linear Transformations, Null Spaces and Ranges}\label{sec:2.1}

\begin{defn}\label{2.1.1}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\).
  We call a function \(\T : \V \to \W\) a \textbf{linear transformation from \(\V\) to \(\W\)} if, for all \(x, y \in \V\) and \(c \in \F\), we have
  \begin{enumerate}
    \item \(\T(x + y) = \T(x) + \T(y)\) and
    \item \(\T(cx) = c\T(x)\).
  \end{enumerate}
  We often simply call \(\T\) \textbf{linear}.
\end{defn}

\begin{note}
  If the underlying field \(\F\) is the field of rational numbers, then \cref{2.1.1}(a) implies \cref{2.1.1}(b) (see \cref{ex:2.1.37}), but, in general \cref{2.1.1}(a)(b) are logically independent.
\end{note}

\begin{prop}\label{2.1.2}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\) and let \(\T : \V \to \W\) be a function.
  \begin{enumerate}
    \item If \(\T\) is linear, then \(\T(\zv_{\V}) = \zv_{\W}\).
    \item \(\T\) is linear if and only if \(\T(cx + y) = c\T(x) + \T(y)\) for all \(x, y \in \V\) and \(c \in \F\).
    \item If \(\T\) is linear, then \(\T(x - y) = \T(x) - \T(y)\) for all \(x, y \in \V\).
    \item \(\T\) is linear if and only if, for \(\seq{x}{1,2,,n} \in \V\) and \(\seq{a}{1,2,,n} \in F\), we have
          \[
            \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n a_i \T(x_i).
          \]
  \end{enumerate}
\end{prop}

\begin{proof}[\pf{2.1.2}(a)]
  We have
  \begin{align*}
             & \T \text{ is linear}                                                                   \\
    \implies & \T(\zv_{\V}) + \T(\zv_{\V}) = \T(\zv_{\V} + \zv_{\V}) &  & \text{(by \cref{2.1.1}(a))} \\
             & = \T(\zv_{\V}) = \T(\zv_{\V}) + \zv_{\W}              &  & \text{(by \ref{vs3})}       \\
    \implies & \T(\zv_{\V}) = \zv_{\W}.                              &  & \text{(by \cref{1.1})}
  \end{align*}
\end{proof}

\begin{proof}[\pf{2.1.2}(b)]
  We have
  \begin{align*}
             & \T \text{ is linear}                                                                                  \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \begin{dcases}
      \T(x + y) = \T(x) + \T(y) \\
      \T(cx) = c\T(x)
    \end{dcases}                    &  & \text{(by \cref{2.1.1})} \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \T(cx + y) = \T(cx) + \T(y) = c\T(x) + \T(y) &  & \text{(by \cref{2.1.1})}
  \end{align*}
  and
  \begin{align*}
             & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \T(cx + y) = c\T(x) + \T(y)                                  \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \begin{dcases}
      \T(x + y) = \T(x) + \T(y)             & \text{if } c = 0        \\
      \T(cx + \zv_{\V}) = c\T(x) + \zv_{\W} & \text{if } y = \zv_{\V}
    \end{dcases}  &  & \text{(by \cref{2.1.2}(a))} \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \begin{dcases}
      \T(x + y) = \T(x) + \T(y) & \text{if } c = 0        \\
      \T(cx) = c\T(x)           & \text{if } y = \zv_{\V}
    \end{dcases} &  & \text{(by \ref{vs3})}       \\
    \implies & \T \text{ is linear}.                                  &  & \text{(by \cref{2.1.1})}
  \end{align*}
  Thus
  \[
    \T \text{ is linear} \iff \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases}, \T(cx + y) = c\T(x) + \T(y).
  \]
\end{proof}

\begin{proof}[\pf{2.1.2}(c)]
  For all \(x, y \in \V\), we have
  \begin{align*}
    \T(x - y) & = \T(x + (-1)y)      &  & \text{(by \cref{1.2}(b))}   \\
              & = \T(x) + \T((-1)y)  &  & \text{(by \cref{2.1.1}(a))} \\
              & = \T(x) + (-1) \T(y) &  & \text{(by \cref{2.1.1}(b))} \\
              & = \T(x) - \T(y).     &  & \text{(by \cref{1.2}(b))}
  \end{align*}
\end{proof}

\begin{proof}[\pf{2.1.2}(d)]
  We have
  \begin{align*}
             & \T \text{ is linear}                                                                                                  \\
    \implies & \begin{dcases}
      \forall \seq{x}{1,2,,n} \in \V \\
      \forall \seq{a}{1,2,,n} \in \F
    \end{dcases},                                                                                           \\
             & \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n \T(a_i x_i) = \sum_{i = 1}^n a_i \T(x_i) &  & \text{(by \cref{2.1.1})}
  \end{align*}
  and
  \begin{align*}
             & \begin{dcases}
      \forall \seq{x}{1,2,,n} \in \V \\
      \forall \seq{a}{1,2,,n} \in \F
    \end{dcases},                                                                 \\
             & \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n a_i \T(x_i) &  & \text{(by \cref{2.1.1})}    \\
    \implies & \begin{dcases}
      \forall x, y \in \V \\
      \forall c \in \F
    \end{dcases},                                                                 \\
             & \T(cx + 1y) = c\T(x) + 1\T(y) = c\T(x) + \T(y)             &  & \text{(by \ref{vs5})}       \\
    \implies & \T \text{ is linear}.                                      &  & \text{(by \cref{2.1.2}(b))}
  \end{align*}
  Thus
  \[
    \T \text{ is linear} \iff \begin{dcases}
      \forall \seq{x}{1,2,,n} \in \V \\
      \forall \seq{a}{1,2,,n} \in \F
    \end{dcases}, \T\pa{\sum_{i = 1}^n a_i x_i} = \sum_{i = 1}^n a_i \T(x_i).
  \]
\end{proof}

\begin{note}
  We generally use \cref{2.1.2}(b) to prove that a given transformation is linear.
\end{note}

\begin{eg}\label{2.1.3}
  For any angle \(\theta\), define \(\T_{\theta} : \R^2 \to \R^2\) by the rule: \(\T_{\theta}(a_1, a_2)\) is the vector obtained by rotating \((a_1, a_2)\) counterclockwise by \(\theta\) if \((a_1, a_2) \neq (0, 0)\), and \(\T_{\theta}(0, 0) = (0, 0)\).
  Then \(\T_{\theta} : \R^2 \to \R^2\) is a linear transformation that is called the \textbf{rotation by \(\theta\)}.

  We determine an explicit formula for \(\T_{\theta}\).
  Fix a nonzero vector \((a_1, a_2) \in \R^2\).
  Let \(\alpha\) be the angle that \((a_1, a_2)\) makes with the positive \(x\)-axis, and let \(r = \sqrt{a_1^2 +a_2^2}\).
  Then \(a_1 = r \cos(\alpha)\) and \(a_2 = r \sin(\alpha)\).
  Also, \(\T_{\theta}(a_1, a_2)\) has length \(r\) and makes an angle \(\alpha + \theta\) with the positive \(x\)-axis.
  It follows that
  \begin{align*}
    \T_{\theta}(a_1, a_2) & = (r \cos(\alpha + \theta), r \sin(\alpha + \theta))                                                                     \\
                          & = (r \cos(\alpha) \cos(\theta) - r \sin(\alpha) \sin(\theta), r \cos(\alpha) \sin(\theta) + r \sin(\alpha) \cos(\theta)) \\
                          & = (a_1 \cos(\theta) - a_2 \sin(\theta), a_1 \sin(\theta) + a_2 \cos(\theta)).
  \end{align*}
  Finally, observe that this same formula is valid for \((a_1 ,a_2) = (0, 0)\).
  It is now easy to show that \(\T_{\theta}\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.3}]
  For all \(x, y \in \R^2\) and \(c \in \R\), we have
  \begin{align*}
    \T_{\theta}(cx + y) & = \T_{\theta}(cx_1 + y_1, cx_2 + y_2)                                              &  & \text{(by \cref{1.2.4})} \\
                        & = ((cx_1 + y_1) \cos(\theta) - (cx_2 + y_2)\sin(\theta),                                                         \\
                        & \quad (cx_1 + y_1) \sin(\theta) + (cx_2 + y_2) \cos(\theta))                       &  & \text{(by \cref{2.1.3})} \\
                        & = c (x_1 \cos(\theta) - x_2 \sin(\theta), x_1 \sin(\theta) + x_2 \cos(\theta))     &  & \text{(by \cref{1.2.1})} \\
                        & \quad + (y_1 \cos(\theta) - y_2 \sin(\theta), y_1 \sin(\theta) + y_2 \cos(\theta))                               \\
                        & = c\T(x_1, x_2) + \T(y_1, y_2)                                                     &  & \text{(by \cref{2.1.3})} \\
                        & = c\T_{\theta}(x) + \T_{\theta}(y).                                                &  & \text{(by \cref{1.2.4})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\T_{\theta}\) is linear.
\end{proof}

\begin{eg}\label{2.1.4}
  Define \(\T : \R^2 \to \R^2\) by \(\T(a_1, a_2) = (a_1, -a_2)\).
  \(\T\) is called the \textbf{reflection about the \(x\)-axis} and \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.4}]
  For all \(x, y \in \R^2\) and \(c \in \R\), we have
  \begin{align*}
    \T(cx + y) & = \T(cx_1 + y_1, cx_2 + y_2)   &  & \text{(by \cref{1.2.4})} \\
               & = (cx_1 + y_1, -cx_2 - y_2)    &  & \text{(by \cref{2.1.4})} \\
               & = c(x_1, -x_2) + (y_1, -y_2)   &  & \text{(by \cref{1.2.1})} \\
               & = c\T(x_1, x_2) + \T(y_1, y_2) &  & \text{(by \cref{2.1.4})} \\
               & = c\T(x) + \T(y).              &  & \text{(by \cref{1.2.4})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.5}
  Define \(\T : \R^2 \to \R^2\) by \(\T(a_1, a_2) = (a_1, 0)\).
  \(\T\) is called the \textbf{projection on the \(x\)-axis} and \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.5}]
  For all \(x, y \in \R^2\) and \(c \in \R\), we have
  \begin{align*}
    \T(cx + y) & = \T(cx_1 + y_1, cx_2 + y_2)   &  & \text{(by \cref{1.2.4})} \\
               & = (cx_1 + y_1, 0)              &  & \text{(by \cref{2.1.5})} \\
               & = c(x_1, 0) + (y_1, 0)         &  & \text{(by \cref{1.2.1})} \\
               & = c\T(x_1, x_2) + \T(y_1, y_2) &  & \text{(by \cref{2.1.5})} \\
               & = c\T(x) + \T(y).              &  & \text{(by \cref{1.2.4})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.6}
  Define \(\T : \ms{m}{n}{\F} \to \ms{n}{m}{\F}\) by \(\T(A) = \tp{A}\), where \(\tp{A}\) is the transpose of \(A\), defined in \cref{1.3.3}.
  Then \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.6}]
  By \cref{ex:1.3.3} and \cref{2.1.2}(b) we see that \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.7}
  Define \(\T : \ps{\R} \to \ps{\R}\) by \(\T(f) = f'\), where \(f'\) denotes the derivative of \(f\).
  Then \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.7}]
  Let \(g, h \in \ps{\R}\) and \(a \in \R\).
  Now
  \[
    \T(ag + h) = (ag + h)' = ag' + h' = a\T(g) + \T(h).
  \]
  So by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.8}
  Let \(\V = \cfs{\R}\), the vector space of continuous real-valued functions on \(\R\).
  Let \(a, b \in \R\), \(a < b\).
  Define \(\T : \V \to \R\) by
  \[
    \T(f) = \int_a^b f(t) \; dt
  \]
  for all \(f \in \V\).
  Then \(\T\) is linear.
\end{eg}

\begin{proof}[\pf{2.1.8}]
  Let \(g, h \in \cfs{\R}\) and \(a \in \R\).
  Now
  \begin{align*}
    \T(cg + h) & = \int_a^b (cg + h)(t) \; dt                  &  & \text{(by \cref{2.1.8})}  \\
               & = \int_a^b cg(t) + h(t) \; dt                 &  & \text{(by \cref{1.2.10})} \\
               & = c \int_a^b g(t) \; dt + \int_a^b h(t) \; dt                                \\
               & = c \T(g) + \T(h).                            &  & \text{(by \cref{2.1.8})}
  \end{align*}
  So by \cref{2.1.2}(b) \(\T\) is linear.
\end{proof}

\begin{eg}\label{2.1.9}
  For vector spaces \(\V\) and \(\W\) over \(\F\), we define the \textbf{identity transformation} \(\IT[\V] : \V \to \V\) by \(\IT[\V](x) = x\) for all \(x \in \V\) and the \textbf{zero transformation} \(\zT : \V \to \W\) by \(\zT(x) = \zv_{\W}\) for all \(x \in \V\).
  It is clear that both of these transformations are linear.
  We often write \(\IT\) instead of \(\IT[\V]\).
\end{eg}

\begin{proof}[\pf{2.1.9}]
  For all \(x, y \in \V\) and \(c \in \F\), we have
  \begin{align*}
    \IT[\V](cx + y) & = cx + y                    &  & \text{(by \cref{2.1.9})} \\
                    & = c \IT[\V](x) + \IT[\V](y) &  & \text{(by \cref{2.1.9})}
  \end{align*}
  and
  \begin{align*}
    \zT(cx + y) & = \zv_{\W}              &  & \text{(by \cref{2.1.9})}  \\
                & = c \zv_{\W}            &  & \text{(by \cref{1.2}(c))} \\
                & = c \zv_{\W} + \zv_{\W} &  & \text{(by \ref{vs3})}     \\
                & = c\T(x) + \T(y).       &  & \text{(by \cref{2.1.9})}
  \end{align*}
  Thus by \cref{2.1.2}(b) \(\IT[\V], \zT\) are linear.
\end{proof}

\begin{defn}\label{2.1.10}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and let \(\T : \V \to \W\) be linear.
  We define the \textbf{null space} (or \textbf{kernel}) \(\ns{\T}\) of \(\T\) to be the set of all vectors \(x\) in \(\V\) such that \(\T(x) = \zv_{\W}\);
  that is, \(\ns{\T} = \set{x \in \V : \T(x) = \zv_{\W}}\).

  We define the \textbf{range} (or \textbf{image}) \(\rg{\T}\) of \(\T\) to be the subset of \(\W\) consisting of all images (under \(\T\)) of vectors in \(\V\);
  that is, \(\rg{\T} = \set{\T(x) : x \in V}\).
\end{defn}

\begin{eg}\label{2.1.11}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and let \(\IT : \V \to \V\) and \(\zT : \V \to \W\) be the identity and zero transformations, respectively.
  Then \(\ns{\IT} = \set{\zv_{\V}}\), \(\rg{\IT} = \V\), \(\ns{\zT} = \V\), and \(\rg{\zT} = \set{\zv_{\W}}\).
\end{eg}

\begin{thm}\label{2.1}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\) and \(\T : \V \to \W\) be linear.
  Then \(\ns{\T}\) and \(\rg{\T}\) are subspaces of \(\V\) and \(\W\) over \(\F\), respectively.
\end{thm}

\begin{proof}[\pf{2.1}]
  To clarify the notation, we use the symbols \(\zv_{\V}\) and \(\zv_{\W}\) to denote the zero vectors of \(\V\) and \(\W\), respectively.

  Since \(\T(\zv_{\V}) = \zv_{\W}\), we have that \(\zv_{\V} \in \ns{\T}\).
  Let \(x, y \in \ns{\T}\) and \(c \in \F\).
  Then \(\T(x + y) = \T(x) + \T(y) = \zv_{\W} +\zv_{\W} = \zv_{\W}\), and \(\T(cx) = c \T(x) = c \zv_{\W} = \zv_{\W}\).
  Hence \(x + y \in \ns{\T}\) and \(cx \in \ns{\T}\), so that \(\ns{\T}\) is a subspace of \(\V\) over \(\F\) (see \cref{1.3}).

  Because \(\T(\zv_{\V}) = \zv_{\W}\), we have that \(\zv_{\W} \in \rg{\T}\).
  Now let \(x, y \in \rg{\T}\) and \(c \in \F\).
  Then there exist \(v\) and \(w\) in \(\V\) such that \(\T(v) = x\) and \(\T(w) = y\).
  So \(\T(v + w) = \T(v) + \T(w) = x + y\), and \(\T(cv) = c \T(v) = cx\).
  Thus \(x + y \in \rg{\T}\) and \(cx \in \rg{\T}\), so \(\rg{\T}\) is a subspace of \(\W\) over \(\F\) (see \cref{1.3}).
\end{proof}

\begin{thm}\label{2.2}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and let \(\T : \V \to \W\) be linear.
  If \(\beta = \set{\seq{v}{1,2,,n}}\) is a basis for \(\V\) over \(\F\), then
  \[
    \rg{\T} = \spn{\T(\beta)} = \spn{\set{\T(v_1), \T(v_2), \dots, \T(v_n)}}.
  \]
\end{thm}

\begin{proof}[\pf{2.2}]
  Clearly \(\T(v_i) \in \rg{\T}\) for each \(i\).
  Because \(\rg{\T}\) is a subspace, \(\rg{\T}\) contains \(\spn{\set{\T(v_1), \T(v_2), \dots, \T(v_n)}} = \spn{\T(\beta)}\) by \cref{1.5}.

  Now suppose that \(w \in \rg{\T}\).
  Then \(w = \T(v)\) for some \(v \in \V\).
  Because \(\beta\) is a basis for \(\V\) over \(\F\), we have
  \[
    v = \sum_{i = 1}^n a_i v_i \quad \text{for some } \seq{a}{1,2,,n} \in \F.
  \]
  Since \(\T\) is linear, it follows that
  \[
    w = \T(v) = \sum_{i = 1}^n a_i \T(v_i) \in \spn{T(\beta)}.
  \]
  So \(\rg{\T}\) is contained in \(\spn{\T(\beta)}\).
\end{proof}

\begin{note}
  It should be noted that \cref{2.2} is true if \(\beta\) is infinite.
  (See \cref{ex:2.1.33}.)
\end{note}

\begin{defn}\label{2.1.12}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and let \(\T : \V \to \W\) be linear.
  If \(\ns{\T}\) and \(\rg{\T}\) are finite-dimensional, then we define the \textbf{nullity} of \(\T\), denoted \(\nt{\T}\), and the \textbf{rank} of \(\T\), denoted \(\rk{\T}\), to be the dimensions of \(\ns{\T}\) and \(\rg{\T}\), respectively.
\end{defn}

\begin{note}
  Reflecting on the action of a linear transformation, we see intuitively that the larger the nullity, the smaller the rank.
  In other words, the more vectors that are carried into \(\zv\), the smaller the range.
  The same heuristic reasoning tells us that the larger the rank, the smaller the nullity.
\end{note}

\begin{thm}[Dimension Theorem]\label{2.3}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and let \(\T : \V \to \W\) be linear.
  If \(\V\) is finite-dimensional, then
  \[
    \nt{\T} + \rk{\T} = \dim(\V).
  \]
\end{thm}

\begin{proof}[\pf{2.3}]
  Suppose that \(\dim(\V) = n\), \(\dim(\ns{\T}) = k\), and \(\set{\seq{v}{1,2,,k}}\) is a basis for \(\ns{\T}\) over \(\F\).
  By the \cref{1.6.19} we may extend \(\set{\seq{v}{1,2,,k}}\) to a basis \(\beta = \set{\seq{v}{1,2,,n}}\) for \(\V\) over \(\F\).
  We claim that \(S = \set{\T(v_{k + 1}), \T(v_{k + 2}), \dots, \T(v_n)}\) is a basis for \(\rg{\T}\) over \(\F\).

  First we prove that \(S\) generates \(\rg{\T}\).
  Using \cref{2.2} and the fact that \(\T(v_i) = \zv\) for \(1 \leq i \leq k\), we have
  \begin{align*}
    \rg{\T} & = \spn{\set{\T(v_1), \T(v_2), \dots, \T(v_n)}}             \\
            & = \spn{\set{\T(v_{k + 1}), \T(v_{k + 2}), \dots, \T(v_n)}} \\
            & = \spn{S}.
  \end{align*}
  Now we prove that \(S\) is linearly independent.
  Suppose that
  \[
    \sum_{i = k + 1}^n b_i \T(v_i) = \zv \quad \text{for } \seq{b}{k + 1,k + 2,,n} \in \F.
  \]
  Using the fact that \(\T\) is linear, we have
  \[
    \T\pa{\sum_{i = k + 1}^n b_i v_i} = \zv.
  \]
  So
  \[
    \sum_{i = k + 1}^n b_i v_i \in \ns{\T}.
  \]
  Hence there exist \(\seq{c}{1,2,,k} \in \F\) such that
  \[
    \sum_{i = k + 1}^n b_i v_i = \sum_{i = 1}^k c_i v_i \quad \text{or} \quad \sum_{i = 1}^k (-c_i) v_i + \sum_{i = k + 1}^n b_i v_i = \zv.
  \]
  Since \(\beta\) is a basis for \(\V\) over \(\F\), we have \(b_i = 0\) for all \(i\).
  Hence \(S\) is linearly independent.
  Notice that this argument also shows that \(\T(v_{k + 1}), \T(v_{k + 2}), \dots, \T(v_n)\) are distinct;
  therefore \(\rk{\T} = n - k\).
\end{proof}

\begin{thm}\label{2.4}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and let \(\T : \V \to \W\) be linear.
  Then \(\T\) is one-to-one if and only if \(\ns{\T} = \set{\zv_{\V}}\).
\end{thm}

\begin{proof}[\pf{2.4}]
  Suppose that \(\T\) is one-to-one and \(x \in \ns{\T}\).
  Then \(\T(x) = \zv_{\W} = \T(\zv_{\V})\).
  Since \(\T\) is one-to-one, we have \(x = \zv_{\V}\).
  Hence \(\ns{\T} = \set{\zv_{\V}}\).

  Now assume that \(\ns{\T} = \set{\zv_{\V}}\), and suppose that \(\T(x) = \T(y)\).
  Then \(\zv_{\W} = \T(x) - \T(y) = \T(x - y)\) by \cref{2.1.2}(c).
  Therefore \(x - y \in \ns{\T} = \set{\zv_{\V}}\).
  So \(x - y = \zv_{\V}\), or \(x = y\).
  This means that \(\T\) is one-to-one.
\end{proof}

\begin{thm}\label{2.5}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\) of equal (finite) dimension, and let \(\T : \V \to \W\) be linear.
  Then the following are equivalent.
  \begin{enumerate}
    \item \(\T\) is one-to-one.
    \item \(\T\) is onto.
    \item \(\rk{\T} = \dim(\V)\)
  \end{enumerate}
\end{thm}

\begin{proof}[\pf{2.5}]
  From the dimension theorem (\cref{2.3}), we have
  \[
    \nt{\T} + \rk{\T} = \dim(\V).
  \]
  Now, with the use of \cref{2.4}, we have that \(\T\) is one-to-one if and only if \(\ns{\T} = \set{\zv_{\V}}\), if and only if \(\nt{\T} = 0\), if and only if \(\rk{\T} = \dim(\V)\), if and only if \(\rk{\T} = \dim(\W)\), and if and only if \(\dim(\rg{\T}) = \dim(\W)\).
  By \cref{1.11}, this equality is equivalent to \(\rg{\T} = \W\), the definition of \(\T\) being onto.
\end{proof}

\begin{note}
  We note that if \(\V\) is not finite-dimensional and \(\T : \V \to \V\) is linear, then it does \emph{not} follow that one-to-one and onto are equivalent.

  The linearity of \(\T\) in \cref{2.4} and \cref{2.5} is essential, for it is easy to construct examples of functions from \(\R\) into \(\R\) that are not one-to-one, but are onto, and vice versa.
\end{note}

\begin{thm}\label{2.6}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and suppose that \(\set{\seq{v}{1,2,,n}}\) is a basis for \(\V\) over \(\F\).
  For \(\seq{w}{1,2,,n}\) in \(\W\), there exists exactly one linear transformation \(\T : \V \to \W\) such that \(\T(v_i) = w_i\) for \(i = 1, 2, \dots, n\).
\end{thm}

\begin{proof}[\pf{2.6}]
  Let \(x \in \V\).
  Then
  \[
    x = \sum_{i = 1}^n a_i v_i
  \]
  where \(\seq{a}{1,2,,n}\) are unique scalars.
  Define
  \[
    \T : \V \to \W \quad \text{by} \quad \T(x) = \sum_{i = 1}^n a_i w_i.
  \]
  \begin{enumerate}
    \item \(\T\) is linear:
          Suppose that \(u, v \in \V\) and \(d \in \F\).
          Then we may write
          \[
            u = \sum_{i = 1}^n b_i v_i \quad \text{and} \quad v = \sum_{i = 1}^n c_i v_i
          \]
          for some scalars \(\seq{b}{1,2,,n}, \seq{c}{1,2,,n}\).
          Thus
          \[
            du + v = \sum_{i = 1}^n (db_i + c_i) v_i.
          \]
          So
          \[
            T(du + v) = \sum_{i = 1}^n (db_i + c_i) w_i = d \sum_{i = 1}^n b_i w_i + \sum_{i = 1}^n c_i w_i = d \T(u) + \T(v).
          \]
    \item Clearly
          \[
            \T(v_i) = w_i \quad \text{for } i = 1, 2, \dots, n.
          \]
    \item \(\T\) is unique:
          Suppose that \(\U : \V \to \W\) is linear and \(\U(v_i) = w_i\) for \(i = 1, 2, \dots, n\).
          Then for \(x \in \V\) with
          \[
            x = \sum_{i = 1}^n a_i v_i,
          \]
          we have
          \[
            \U(x) = \sum_{i = 1}^n a_i \U(v_i) = \sum_{i = 1}^n a_i w_i = \T(x).
          \]
          Hence \(\U = \T\).
  \end{enumerate}
\end{proof}

\begin{cor}\label{2.1.13}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), and suppose that \(\V\) has a finite basis \(\set{\seq{v}{1,2,,n}}\) over \(\F\).
  If \(\U, \T : \V \to \W\) are linear and \(\U(v_i) = \T(v_i)\) for \(i = 1, 2, \dots, n\), then \(\U = \T\).
\end{cor}

\begin{proof}[\pf{2.1.13}]
  Since \(\U(v_i) = \T(v_i)\) for all \(i = 1, 2, \dots, n\), by \cref{2.6} we know that \(\U = \T\).
\end{proof}

\exercisesection

\setcounter{ex}{5}
\begin{ex}\label{ex:2.1.6}
  Define \(\T : \ms{n}{n}{\F} \to \F\) by \(\T(A) = \tr[A]\).
  Prove that \(\T\) is a linear transformation, and find bases for both \(\ns{\T}\) and \(\rg{\T}\) over \(\F\).
  Then compute the nullity and rank of \(\T\), and verify the dimension theorem.
  Finally, use the appropriate theorems in \cref{sec:2.1} to determine whether \(\T\) is one-to-one or onto.
\end{ex}

\begin{proof}[\pf{ex:2.1.6}]
  Let \(A, B \in \ms{n}{n}{\F}\) and let \(c \in \F\).
  First we show that \(\T\) is linear.
  Since
  \begin{align*}
    \T(cA + B) & = \tr[cA + B]                                       &  & \text{(by \cref{ex:2.1.6})}  \\
               & = \sum_{i = 1}^n \pa{cA + B}_{i i}                  &  & \text{(by \cref{1.3.9})}     \\
               & = \sum_{i = 1}^n \pa{cA_{i i} + B_{i i}}            &  & \text{(by \cref{1.2.9})}     \\
               & = c \sum_{i = 1}^n A_{i i} + \sum_{i = 1}^n B_{i i} &  & (A_{i i}, B_{i i}, c \in \F) \\
               & = c \tr[A] + \tr[B]                                 &  & \text{(by \cref{1.3.9})}     \\
               & = c \T(A) + \T(B),                                  &  & \text{(by \cref{ex:2.1.6})}
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T\) is linear.

  Next we find a basis for \(\ns{\T}\) over \(\F\).
  Let \(\W\) and \(\beta\) be the sets defined in \cref{ex:1.6.15}.
  From \cref{ex:1.6.15} we see that \(\W = \ns{\T}\) and \(\beta\) is a basis for \(\ns{\T}\) over \(\F\).
  Thus we have \(\dim(\ns{\T}) = \nt{\T} = n^2 - 1\).

  Next we find a basis for \(\rg{\T}\) over \(\F\).
  Since \(\tr[A] \in \F\) for all \(A \in \ms{n}{n}{\F}\), we know that \(\tr[\ms{n}{n}{\F}] \subseteq \F\).
  Since
  \[
    \forall c \in \F, \tr\begin{pmatrix}
      c      & 0      & \cdots & 0      \\
      0      & 0      & \cdots & 0      \\
      \vdots & \vdots & \ddots & \vdots \\
      0      & 0      & \cdots & 0
    \end{pmatrix} = c,
  \]
  we know that \(\F \subseteq \tr[\ms{n}{n}{\F}]\).
  Thus we have \(\rg{\T} = \T(\ms{n}{n}{\F}) = \tr[\ms{n}{n}{\F}] = \F\), and \(\dim(\rg{\T}) = \rk{\T} = 1\).

  From the proofs above we see that
  \[
    \dim(\ms{n}{n}{\F}) = n^2 = (n^2 - 1) + 1 = \nt{\T} + \rk{\T},
  \]
  thus the dimension theorem (\cref{2.3}) holds.
  Since \(\ns{\T} \neq \set{\zm}\), by \cref{2.4} we know that \(\T\) is not one-to-one.
  Since \(\rg{\T} = \F\), we know that \(\T\) is onto.
\end{proof}

\setcounter{ex}{12}
\begin{ex}\label{ex:2.1.13}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\), let \(\T : \V \to \W\) be linear, and let \(\set{\seq{w}{1,2,,k}}\) be a linearly independent subset of \(\rg{\T}\).
  Prove that if \(S = \set{\seq{v}{1,2,,k}}\) is chosen so that \(\T(v_i) = w_i\) for \(i = 1, 2, \dots, k\), then \(S\) is linearly independent.
\end{ex}

\begin{proof}[\pf{ex:2.1.13}]
  Let \(\seq{a}{1,2,,k} \in \F\).
  Since
  \begin{align*}
             & \sum_{i = 1}^k a_i v_i = \zv_{\V}                                         \\
    \implies & \T\pa{\sum_{i = 1}^k a_i v_i} = \zv_{\W} &  & \text{(by \cref{2.1.2}(a))} \\
    \implies & \sum_{i = 1}^k a_i \T(v_i) = \zv_{\W}    &  & \text{(by \cref{2.1.2}(d))} \\
    \implies & \sum_{i = 1}^k a_i w_i = \zv_{\W}                                         \\
    \implies & \seq[=]{a}{1,2,,k} = 0,                  &  & \text{(by \cref{1.5.3})}
  \end{align*}
  by \cref{1.5.3} we know that \(\set{\seq{v}{1,2,,k}}\) is linearly independent.
\end{proof}

\begin{ex}\label{ex:2.1.14}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\) and \(\T : \V \to \W\) be linear.
  \begin{enumerate}
    \item Prove that \(\T\) is one-to-one if and only if \(\T\) carries linearly independent subsets of \(\V\) onto linearly independent subsets of \(\W\).
    \item Suppose that \(\T\) is one-to-one and that \(S\) is a subset of \(\V\).
          Prove that \(S\) is linearly independent if and only if \(\T(S)\) is linearly independent.
    \item Suppose \(\beta = \set{\seq{v}{1,2,,n}}\) is a basis for \(\V\) over \(\F\) and \(\T\) is one-to-one and onto.
          Prove that \(\T(\beta) = \set{\T(v_1), \T(v_2), \dots, \T(v_n)}\) is a basis for \(\W\) over \(\F\).
  \end{enumerate}
\end{ex}

\begin{proof}[\pf{ex:2.1.14}(a)]
  First suppose that \(\T\) is one-to-one.
  Let \(S\) be a linearly independent subset of \(\V\).
  Note that \(\V\) can be infinite-dimensional and thus \(S\) can be infinite.
  Since
  \begin{align*}
             & \begin{dcases}
      \forall \seq{w}{1,2,,k} \in \T(S) \\
      \forall \seq{a}{1,2,,k} \in \F
    \end{dcases}, \sum_{i = 1}^k a_i w_i = \zv_{\W}                                    \\
    \implies & \exists \seq{v}{1,2,,k} \in S :                                                                  \\
             & \begin{dcases}
      \forall i \in \set{1, 2, \dots, k}, \T(v_i) = w_i \\
      \sum_{i = 1}^k a_i w_i = \sum_{i = 1}^k a_i \T(v_i) = \T\pa{\sum_{i = 1}^k a_i v_i} = \zv_{\W} = \T(\zv_{\V})
    \end{dcases}                                    &  & \text{(by \cref{2.1.2})}      \\
    \implies & \sum_{i = 1}^k a_i v_i = \zv_{\V}                             &  & \text{(\(\T\) is one-to-one)} \\
    \implies & \seq[=]{a}{1,2,,k} = 0,                                       &  & \text{(by \cref{1.5.3})}
  \end{align*}
  by \cref{1.5.3} we know that \(\T(S)\) is linearly independent.
  Since \(S\) is arbitrary, we conclude that \(\T\) carries linearly independent subsets of \(\V\) onto linearly independent subsets of \(\W\).

  Now suppose that \(\T\) carries linearly independent subsets of \(\V\) onto linearly independent subsets of \(\W\).
  Since
  \begin{align*}
             & \forall x, y \in \V, x \neq y                                                    \\
    \implies & x - y \neq \zv_{\V}                                                              \\
    \implies & \set{x - y} \text{ is linearly independent}     &  & \text{(by \cref{1.5.4}(b))} \\
    \implies & \set{\T(x - y)} \text{ is linearly independent} &  & \text{(by hypothesis)}      \\
    \implies & \T(x - y) \neq \zv_{\W}                         &  & \text{(by \cref{1.5.2})}    \\
    \implies & \T(x) - \T(y) \neq \zv_{\W}                     &  & \text{(by \cref{2.1.2}(c))} \\
    \implies & \T(x) \neq \T(y),
  \end{align*}
  we know that \(\T\) is one-to-one.
  From all proofs above we conclude that \(\T\) is one-to-one if and only if \(\T\) carries linearly independent subsets of \(\V\) onto linearly independent subsets of \(\W\).
\end{proof}

\begin{proof}[\pf{ex:2.1.14}(b)]
  By \cref{ex:2.1.14}(a) and \cref{ex:2.1.13} we are done.
\end{proof}

\begin{proof}[\pf{ex:2.1.14}(c)]
  Since \(\T\) is one-to-one, by \cref{ex:2.1.14}(b) we know that \(\T(\beta)\) is linearly independent.
  Since \(\T\) is onto, by \cref{2.2} we know that \(\spn{\T(\beta)} = \rg{\T} = \W\).
  Thus by \cref{1.6.1} \(\T(\beta)\) is a basis for \(\W\) over \(\F\).
\end{proof}

\begin{ex}\label{ex:2.1.15}
  Define
  \[
    \T : \ps{\R} \to \ps{\R} \quad \text{by} \quad \T(f) = \int_0^x f(t) \; dt.
  \]
  Prove that \(\T\) is linear and one-to-one, but not onto.
\end{ex}

\begin{proof}[\pf{ex:2.1.15}]
  First we show that \(\T\) is linear.
  Let \(f, g \in \ps{\R}\) and let \(c \in \R\).
  Since
  \begin{align*}
    \T(cf + g) & = \int_0^x (cf + g)(t) \; dt                  &  & \text{(by \cref{ex:2.1.15})} \\
               & = \int_0^x cf(t) + g(t) \; dt                 &  & \text{(by \cref{1.2.10})}    \\
               & = c \int_0^x f(t) \; dt + \int_0^x g(t) \; dt                                   \\
               & = c \T(f) + \T(g),
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T\) is linear.

  Next we show that \(\T\) is one-to-one.
  Let \(\zv : \R \to \R\) denote the zero function.
  Since
  \[
    \forall f \in \ps{\R}, \int_0^x f(t) \; dt = \zv \implies f = \zv \implies \ns{\T} = \set{\zv},
  \]
  by \cref{2.4} we know that \(\T\) is one-to-one.

  Now we show that \(\T\) is not onto.
  Let \(c \in \F \setminus \set{0}\).
  Since \(c \in \ps{\R}\) and no polynomial function has indefinite integral equals to \(c\), we know that \(\T\) is not onto.
\end{proof}

\begin{ex}\label{ex:2.1.16}
  Let \(\T : \ps{\R} \to \ps{\R}\) be defined by \(\T(f) = f'\).
  Recall that \(\T\) is linear (\cref{2.1.7}).
  Prove that \(\T\) is onto, but not one-to-one.
\end{ex}

\begin{proof}[\pf{ex:2.1.16}]
  First we show that \(\T\) is onto.
  Let \(f \in \ps{\R}\).
  Since
  \begin{align*}
             & f \in \ps{\R}                                                          \\
    \implies & \exists \seq{a}{0,1,,n} \in \R : f(x) = a_0 + a_1 x + \cdots + a_n x^n \\
    \implies & \begin{dcases}
      x \mapsto a_0 x + \frac{a_1}{2} x^2 + \cdots + \frac{a_n}{n + 1} x^{n + 1} \in \ps{\R} \\
      (x \mapsto a_0 x + \frac{a_1}{2} x^2 + \cdots + \frac{a_n}{n + 1} x^{n + 1})' = f
    \end{dcases}
  \end{align*}
  and \(f\) is arbitrary, we know that \(\T\) is onto.

  Now we show that \(\T\) is not one-to-one.
  Observe that
  \begin{align*}
     & x \mapsto x \in \ps{\R};          \\
     & x \mapsto x + 1 \in \ps{\R};      \\
     & (x \mapsto x)' = 1;               \\
     & (x \mapsto x + 1)' = 1;           \\
     & x \mapsto x \neq x \mapsto x + 1.
  \end{align*}
  Thus \(\T\) is not one-to-one.
\end{proof}

\begin{ex}\label{ex:2.1.17}
  Let \(\V\) and \(\W\) be finite-dimensional vector spaces over \(\F\) and \(\T : \V \to \W\) be linear.
  \begin{enumerate}
    \item Prove that if \(\dim(\V) < \dim(\W)\), then \(\T\) cannot be onto.
    \item Prove that if \(\dim(\V) > \dim(\W)\), then \(\T\) cannot be one-to-one.
  \end{enumerate}
\end{ex}

\begin{proof}[\pf{ex:2.1.17}(a)]
  Suppose that \(\dim(\V) < \dim(\W)\).
  Suppose for sake of contradiction that \(\T\) is onto.
  Let \(\beta_{\W} = \set{\seq{w}{1,2,,n}}\) be a basis for \(\W\) over \(\F\).
  Since \(\T\) is onto, there exists a set \(\beta_{\V} = \set{\seq{v}{1,2,,n}}\) such that \(\T(v_i) = w_i\) for all \(i \in \set{1, 2, \dots, n}\).
  But by \cref{ex:2.1.13} we know that \(\beta_{\V}\) is linearly independent, by \cref{1.6.8} this means \(\dim(\V) \geq \dim(\W)\), a contradiction.
  Thus \(\T\) cannot be onto.
\end{proof}

\begin{proof}[\pf{ex:2.1.17}(b)]
  Suppose that \(\dim(\V) > \dim(\W)\).
  Suppose for sake of contradiction that \(\T\) is one-to-one.
  Since \(\T\) is one-to-one, by \cref{2.4} we know that \(\ns{\T} = \set{\zv_{\V}}\).
  Thus we have
  \begin{align*}
    \dim(\V) & = \rk{\T} + \nt{\T} &  & \text{(by \cref{2.3})}    \\
             & = \rk{\T} + 0       &  & \text{(by \cref{1.6.9})}  \\
             & = \rk{\T}                                          \\
             & = \dim(\rg{\T})     &  & \text{(by \cref{2.1.12})} \\
             & \leq \dim(\W).      &  & \text{(by \cref{1.11})}
  \end{align*}
  But this contradict to the fact that \(\dim(\V) > \dim(\W)\).
  Thus \(\T\) cannot be one-to-one.
\end{proof}

\setcounter{ex}{19}
\begin{ex}\label{ex:2.1.20}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\) with subspaces \(\V_1\) and \(\W_1\) over \(\F\), respectively.
  If \(\T : \V \to \W\) is linear, prove that \(\T(\V_1)\) is a subspace of \(\W\) over \(\F\) and that \(\set{x \in \V : \T(x) \in \W_1}\) is a subspace of \(\V\) over \(\F\).
\end{ex}

\begin{proof}[\pf{ex:2.1.20}]
  First we show that \(\T(\V_1)\) is a subspace of \(\W\) over \(\F\).
  Let \(w_1, w_2 \in \T(\V_1)\) and let \(c \in \F\).
  Since
  \begin{align*}
             & \zv_{\V} \in \V_1                    &  & \text{(by \cref{1.3}(a))}   \\
    \implies & \T(\zv_{\V}) = \zv_{\W} \in \T(\V_1) &  & \text{(by \cref{2.1.2}(a))}
  \end{align*}
  and
  \begin{align*}
             & w_1, w_2 \in \T(\V_1)                                                                    \\
    \implies & \exists v_1, v_2 \in \V_1 : \begin{dcases}
      \T(v_1) = w_1 \\
      \T(v_2) = w_2
    \end{dcases}                                   \\
    \implies & \begin{dcases}
      v_1 + v_2 \in \V_1 \\
      c v_1 \in \V_1
    \end{dcases}                             &  & \text{(by \cref{1.3}(b)(c))} \\
    \implies & \begin{dcases}
      w_1 + w_2 = \T(v_1) + \T(v_2) = \T(v_1 + v_2) \in \T(\V_1) \\
      c w_1 = c \T(v_1) = \T(c v_1) \in \T(\V_1)
    \end{dcases},                            &  & \text{(by \cref{2.1.1})}
  \end{align*}
  by \cref{1.3} we know that \(\T(\V_1)\) is a subspace of \(\W\) over \(\F\).

  Now we show that \(\V' = \set{x \in \V : \T(x) \in \W_1}\) is a subspace of \(\V\) over \(\F\).
  Let \(v_1, v_2 \in \V'\) and let \(c \in \F\).
  Since
  \begin{align*}
             & \zv_{\V} \in \V                  &  & \text{(by \cref{1.3}(a))}   \\
    \implies & \T(\zv_{\V}) = \zv_{\W} \in \W   &  & \text{(by \cref{2.1.2}(a))} \\
    \implies & \T(\zv_{\V}) = \zv_{\W} \in \W_1 &  & \text{(by \cref{1.3}(a))}   \\
    \implies & \zv_{\V} \in \V'
  \end{align*}
  and
  \begin{align*}
             & v_1, v_2 \in \V'                                              \\
    \implies & \T(v_1), \T(v_2) \in \W_1                                     \\
    \implies & \begin{dcases}
      \T(v_1) + \T(v_2) \in \W_1 \\
      c \T(v_1) \in \W_1
    \end{dcases}  &  & \text{(by \cref{1.3}(b)(c))} \\
    \implies & \begin{dcases}
      \T(v_1) + \T(v_2) = \T(v_1 + v_2) \in \W_1 \\
      c \T(v_1) = \T(c v_1) \in \W_1
    \end{dcases}  &  & \text{(by \cref{2.1.1})}     \\
    \implies & \begin{dcases}
      v_1 + v_2 \in \V' \\
      c v_1 \in \V'
    \end{dcases},
  \end{align*}
  by \cref{1.3} we know that \(\V'\) is a subspace of \(\V\) over \(\F\).
\end{proof}

\begin{ex}\label{ex:2.1.21}
  Let \(\V\) be the vector space of sequences over \(\F\) described in \cref{1.2.13}.
  Define the functions \(\T, \U : \V \to \V\) by
  \[
    \T(\seq{a}{1,2,}) = \tuple{a}{2,3,} \quad \text{and} \quad \U(\seq{a}{1,2,}) = (0, \seq{a}{1,2,}).
  \]
  \(\T\) and \(\U\) are called the \textbf{left shift} and \textbf{right shift} operators on \(\V\), respectively.
  \begin{enumerate}
    \item Prove that \(\T\) and \(\U\) are linear.
    \item Prove that \(\T\) is onto, but not one-to-one.
    \item Prove that \(\U\) is one-to-one, but not onto.
  \end{enumerate}
\end{ex}

\begin{proof}[\pf{ex:2.1.21}(a)]
  Let \(\set{a_n}, \set{b_n} \in \V\) and let \(t \in \F\).
  Since
  \begin{align*}
    \T(c \set{a_n} + \set{b_n}) & = \T(\set{c a_n + b_n})                   &  & \text{(by \cref{1.2.13})}    \\
                                & = \T(c a_1 + b_1, c a_2 + b_2, \dots)                                       \\
                                & = (c a_2 + b_2, c a_3 + b_3, \dots)       &  & \text{(by \cref{ex:2.1.21})} \\
                                & = c \tuple{a}{2,3,} + \tuple{b}{2,3,}     &  & \text{(by \cref{1.2.13})}    \\
                                & = c \T(\seq{a}{1,2,}) + \T(\seq{b}{1,2,}) &  & \text{(by \cref{ex:2.1.21})} \\
                                & = c \T(\set{a_n}) + \T(\set{b_n}),
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T\) is linear.
  Since
  \begin{align*}
    \U(c \set{a_n} + \set{b_n}) & = \U(\set{c a_n + b_n})                     &  & \text{(by \cref{1.2.13})}    \\
                                & = \U(c a_1 + b_1, c a_2 + b_2, \dots)                                         \\
                                & = (0, c a_1 + b_1, c a_2 + b_2, \dots)      &  & \text{(by \cref{ex:2.1.21})} \\
                                & = c (0, \seq{a}{1,2,}) + (0, \seq{b}{1,2,}) &  & \text{(by \cref{1.2.13})}    \\
                                & = c \U(\seq{a}{1,2,}) + \U(\seq{b}{1,2,})   &  & \text{(by \cref{ex:2.1.21})} \\
                                & = c \U(\set{a_n}) + \U(\set{b_n}),
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\U\) is linear.
\end{proof}

\begin{proof}[\pf{ex:2.1.21}(b)]
  Since
  \[
    \forall \set{a_n} \in \V, \T(0, \seq{a}{1,2,}) = \tuple{a}{1,2,},
  \]
  we know that \(\T\) is onto.
  Since
  \[
    \forall \set{a_n} \in \V, \T(0, \seq{a}{1,2,}) = \tuple{a}{1,2,} = \T(1, \seq{a}{1,2,}),
  \]
  we know that \(\T\) is not one-to-one.
\end{proof}

\begin{proof}[\pf{ex:2.1.21}(c)]
  Since
  \begin{align*}
             & \forall \set{a_n}, \set{b_n} \in \V, \set{a_n} \neq \set{b_n} \\
    \implies & \tuple{a}{1,2,} \neq \tuple{b}{1,2,}                          \\
    \implies & (0, \seq{a}{1,2,}) \neq (0, \seq{b}{1,2,})                    \\
    \implies & \U(\seq{a}{1,2,}) \neq \U(\seq{b}{1,2,}),
  \end{align*}
  we know that \(\U\) is one-to-one.
  Since
  \[
    \forall \set{a_n} \in \V, (1, \seq{a}{1,2,}) \notin \T(\V),
  \]
  we know that \(\U\) is not onto.
\end{proof}

\begin{ex}\label{ex:2.1.22}
  Let \(\T: \vs{F}^n \to \F\) be linear.
  Show that
  \[
    \forall x = \tuple{x}{1,2,,n} \in \vs{F}^n, \exists \seq{a}{1,2,,n} \in \F : \T(\seq{x}{1,2,,n}) = \sum_{i = 1}^n a_i x_i.
  \]
  State and prove an analogous result for \(\T : \vs{F}^n \to \vs{F}^m\).
\end{ex}

\begin{proof}[\pf{ex:2.1.22}]
  For all \(i \in \set{1, \dots, n}\), defined \(e_i \in \vs{F}^n\) as in \cref{1.6.3}.
  We claim that if \(\T : \vs{F}^n \to \vs{F}^m\) is linear, then
  \[
    \forall x \in \vs{F}^n, \exists \seq{a}{1,2,,n} \in \vs{F}^m : \T(x) = \sum_{i = 1}^n x_i a_i.
  \]
  Since
  \begin{align*}
             & \vs{F}^n = \spn{\seq{e}{1,2,,n}}                                       &  & \text{(by \cref{1.6.3})}    \\
    \implies & \forall x \in \vs{F}^n, x = \tuple{x}{1,2,,n} = \sum_{i = 1}^n x_i e_i &  & \text{(by \cref{1.4.3})}    \\
    \implies & \forall x \in \vs{F}^n, \T(x) = \sum_{i = 1}^n x_i \T(e_i),            &  & \text{(by \cref{2.1.2}(d))}
  \end{align*}
  by setting \(\T(e_i) = a_i\) for all \(i \in \set{1, 2, \dots, n}\) we see that our claim is true.
  In particular, when \(m = 1\) we see that
  \[
    \forall x \in \vs{F}^n, \exists \seq{a}{1,2,,n} \in \F : \T(x) = \sum_{i = 1}^n x_i a_i = \sum_{i = 1}^n a_i x_i.
  \]
\end{proof}

\begin{defn}\label{2.1.14}
  Let \(\V\) be a vector space over \(\F\) and \(\W_1\) and \(\W_2\) be subspaces of \(\V\) over \(\F\) such that \(V = \W_1 \oplus \W_2\).
  (See \cref{1.3.11}.)
  A function \(\T : \V \to \V\) is called a \textbf{projection on \(\W_1\) along \(\W_2\)} if, for \(x = x_1 + x_2\) with \(x_1 \in \W_1\) and \(x_2 \in \W_2\), we have \(\T(x) = x_1\).
\end{defn}

\setcounter{ex}{25}
\begin{ex}\label{ex:2.1.26}
  Using the notation in \cref{2.1.14}, assume that \(\T : \V \to \V\) is the projection on \(\W_1\) along \(\W_2\).
  \begin{enumerate}
    \item Prove that \(\T\) is linear and \(\W_1 = \set{x \in \V : \T(x) = x}\).
    \item Prove that \(\W_1 = \rg{\T}\) and \(\W_2 = \ns{\T}\).
    \item Describe \(\T\) if \(\W_1 = \V\).
    \item Describe \(\T\) if \(\W_1\) is the zero subspace.
  \end{enumerate}
\end{ex}

\begin{proof}[\pf{ex:2.1.26}(a)]
  First we show that \(\T\) is linear.
  Let \(x, y \in \V\) and let \(c \in \F\).
  Since
  \begin{align*}
             & \V = \W_1 \oplus \W_2                                                                                           \\
    \implies & \exists (x_1, x_2), (y_1, y_2) \in \W_1 \times \W_2 : \begin{dcases}
      x = x_1 + x_2 \\
      y = y_1 + y_2
    \end{dcases} &  & \text{(by \cref{1.3.11})} \\
    \implies & \T(cx + y) = \T(c (x_1 + x_2) + y_1 + y_2)                                                                      \\
             & = \T(c x_1 + y_1 + c x_2 + y_2) = c x_1 + y_1 = c \T(x) + \T(y),                 &  & \text{(by \cref{2.1.14})}
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T\) is linear.

  Now we show that \(\W_1 = \set{x \in \V : \T(x) = x}\).
  Since
  \begin{align*}
             & \zv \in \W_2                                &  & \text{(by \cref{1.3}(a))} \\
    \implies & \forall x \in \W_1, x = x + \zv             &  & \text{(by \ref{vs3})}     \\
    \implies & \forall x \in \W_1, \T(x) = \T(x + \zv) = x &  & \text{(by \cref{2.1.14})} \\
    \implies & \W_1 \subseteq \set{x \in \V : \T(x) = x}
  \end{align*}
  and
  \begin{align*}
             & \forall x \in \V, \T(x) = x                                               \\
    \implies & x = \T(x) \in \W_1                         &  & \text{(by \cref{2.1.14})} \\
    \implies & \set{x \in \V : \T(x) = x} \subseteq \W_1,
  \end{align*}
  we know that \(\W_1 = \set{x \in \V : \T(x) = x}\).
\end{proof}

\begin{proof}[\pf{ex:2.1.26}(b)]
  First we show that \(\W_1 = \rg{\T}\).
  Since
  \begin{align*}
             & \W_1 = \set{x \in \V : \T(x) = x} &  & \text{(by \cref{ex:2.1.26}(a))} \\
    \implies & \W_1 \subseteq \rg{\T}            &  & \text{(by \cref{2.1.10})}
  \end{align*}
  and
  \begin{align*}
             & \forall x \in \V, \T(x) \in \W_1 &  & \text{(by \cref{2.1.14})} \\
    \implies & \rg{\T} \subseteq \W_1,
  \end{align*}
  we know that \(\W_1 = \rg{\T}\).

  Now we show that \(\W_2 = \ns{\T}\).
  Since
  \begin{align*}
             & \zv \in \W_1                    &  & \text{(by \cref{1.3}(a))} \\
    \implies & \forall x \in \W_2, x = \zv + x &  & \text{(by \ref{vs3})}     \\
    \implies & \forall x \in \W_2, \T(x) = \zv &  & \text{(by \cref{2.1.14})} \\
    \implies & \W_2 \subseteq \ns{\T}          &  & \text{(by \cref{2.1.10})}
  \end{align*}
  and
  \begin{align*}
             & \ns{\T} \subseteq \V                                                           &  & \text{(by \cref{2.1.10})} \\
    \implies & \forall x \in \ns{\T}, \exists (x_1, x_2) \in \W_1 \times \W_2 : x = x_1 + x_2 &  & \text{(by \cref{1.3.11})} \\
    \implies & \forall x \in \ns{\T}, \exists (x_1, x_2) \in \W_1 \times \W_2 :                                              \\
             & \T(x) = \T(x_1 + x_2) = \zv = x_1                                              &  & \text{(by \cref{2.1.14})} \\
    \implies & \forall x \in \ns{\T}, \exists (x_1, x_2) \in \W_1 \times \W_2 :                                              \\
             & x = x_1 + x_2 = \zv + x_2 = x_2 \in \W_2                                       &  & \text{(by \ref{vs3})}     \\
    \implies & \ns{\T} \subseteq \W_2,
  \end{align*}
  we know that \(\W_2 = \ns{\T}\).
\end{proof}

\begin{proof}[\pf{ex:2.1.26}(c)]
  We have
  \begin{align*}
             & \begin{dcases}
      \V = \W_1 \oplus \W_2 \\
      \V = \W_1
    \end{dcases}                                                            \\
    \implies & \W_1 \cap \W_2 = \V \cap \W_2 = \W_2 = \set{\zv} &  & \text{(by \cref{1.3.11})}       \\
    \implies & \ns{\T} = \W_2 = \set{\zv}                       &  & \text{(by \cref{ex:2.1.26}(b))} \\
    \implies & \T \text{ is one-to-one}                         &  & \text{(by \cref{2.4})}          \\
    \implies & \T \text{ is onto}.                              &  & \text{(by \cref{2.5})}
  \end{align*}
\end{proof}

\begin{proof}[\pf{ex:2.1.26}(d)]
  We have
  \begin{align*}
             & \W_1 = \set{\zv}                                                            \\
    \implies & \V = \W_1 \oplus \W_2 = \W_2           &  & \text{(by \cref{1.3.11})}       \\
             & = \ns{\T}                              &  & \text{(by \cref{ex:2.1.26}(b))} \\
    \implies & \forall x \in \V, \T(x) = \zv          &  & \text{(by \cref{2.1.10})}       \\
    \implies & \T \text{ is the zero transformation}. &  & \text{(by \cref{2.1.9})}
  \end{align*}
\end{proof}

\begin{ex}\label{ex:2.1.27}
  Suppose that \(\W\) is a subspace of a finite-dimensional vector space \(\V\) over \(\F\).
  \begin{enumerate}
    \item Prove that there exists a subspace \(\W'\) and a function \(\T : \V \to \V\) such that \(\T\) is a projection on \(\W\) along \(\W'\).
    \item Give an example of a subspace \(\W\) of a vector space \(\V\) over \(\F\) such that there are two projections on \(\W\) along two (distinct) subspaces.
  \end{enumerate}
\end{ex}

\begin{proof}[\pf{ex:2.1.27}(a)]
  Let \(\beta_{\W} = \set{\seq{v}{1,2,,k}}\) be a basis for \(\V\) over \(\F\).
  By \cref{1.6.19} we can extend \(\beta_{\W}\) to \(\beta = \set{\seq{v}{1,2,,n}}\) such that \(\beta\) is a basis for \(\V\) over \(\F\).
  Let \(\beta_{\W'} = \beta \setminus \beta_{\W}\) and let \(\W' = \spn{\beta_{\W'}}\).
  By \cref{1.5} we know that \(\W'\) is a subspace of \(\V\) over \(\F\).

  First we claim that \(\W \cap \W' = \set{\zv}\).
  Let \(v \in \W \cap \W'\).
  Then we have
  \begin{align*}
             & v \in \W \cap \W'                                                                                                                \\
    \implies & \exists \seq{a}{1,2,,k,k + 1,,n} \in \F : v = \sum_{i = 1}^k a_i v_i = \sum_{i = k + 1}^n a_i v_i &  & \text{(by \cref{1.4.3})}  \\
    \implies & \exists \seq{a}{1,2,,k,k + 1,,n} \in \F :                                                                                        \\
             & \sum_{i = 1}^k a_i v_i + \sum_{i = k + 1}^n (-a_i) v_i = \zv                                      &  & \text{(by \cref{1.2.1})}  \\
    \implies & \seq[=]{a}{1,2,,n} = 0                                                                            &  & \text{(by \cref{1.5.3})}  \\
    \implies & v = \zv                                                                                           &  & \text{(by \cref{1.2}(a))} \\
    \implies & \W \cap \W' \subseteq \set{\zv}                                                                                                  \\
    \implies & \W \cap \W' = \set{\zv}.                                                                          &  & \text{(by \cref{1.3}(a))}
  \end{align*}

  Next we claim that \(\V = \W \oplus \W'\).
  Since
  \begin{align*}
             & \forall v \in \V, \exists \seq{a}{1,2,,n} \in \F : v = \sum_{i = 1}^n a_i v_i &  & \text{(by \cref{1.6.1})}        \\
             & = \sum_{i = 1}^k a_i v_i + \sum_{i = k + 1}^n a_i v_i                         &  & \text{(by \cref{1.2.1})}        \\
    \implies & \forall v \in \V, \exists (u, u') \in \W \times \W' : v = u + u'              &  & \text{(by \cref{1.4.3})}        \\
    \implies & \V \subseteq \W + \W'                                                         &  & \text{(by \cref{1.3.10})}       \\
    \implies & \V = \W + \W'                                                                 &  & \text{(by \cref{ex:1.3.23}(a))}
  \end{align*}
  and \(\W \cap \W' = \set{\zv}\), by \cref{1.3.11} we know that \(\V = \W \oplus \W'\).

  Since \(\beta\) is a basis for \(\V\) over \(\F\), by \cref{1.8} we know that
  \[
    \forall v \in \V, \exists \seq{a}{1,2,,n} \in \F : v = \sum_{i = 1}^n a_i v_i.
  \]
  Now we define a function \(\T\) as follow:
  \[
    \forall v \in \V, \T(v) = \sum_{i = 1}^k a_i v_i.
  \]
  We claim that \(\T\) is a projection on \(\W\) along \(\W'\).
  Since
  \begin{align*}
             & \forall v \in \V, \T(v) = \T\pa{\sum_{i = 1}^n a_i v_i}                                                             \\
             & = \T\pa{\sum_{i = 1}^k a_i v_i + \sum_{i = k + 1}^n a_i v_i} = \sum_{i = 1}^k a_i v_i                               \\
    \implies & \forall v \in \V, \exists (u, u') \in \W \times \W' : \T(v) = \T(u + u') = u,         &  & \text{(by \cref{1.4.3})}
  \end{align*}
  by \cref{2.1.14} we know that \(\T\) is a projection on \(\W\) along \(\W'\).
\end{proof}

\begin{proof}[\pf{ex:2.1.27}(b)]
  See Exercise 2.1.24.
\end{proof}

\begin{defn}\label{2.1.15}
  Let \(\V\) be a vector space over \(\F\), and let \(\T : \V \to \V\) be linear.
  A subspace \(\W\) of \(\V\) over \(\F\) is said to be \textbf{\(\T\)-invariant} if \(\T(x) \in \W\) for every \(x \in \W\), that is, \(\T(\W) \subseteq \W\).
  If \(\W\) is \(\T\)-invariant, we define the \textbf{restriction of \(\T\) on \(\W\)} to be the function \(\T_{\W} : \W \to \W\) defined by \(\T_{\W}(x) = \T(x)\) for all \(x \in \W\).
\end{defn}

\cref{ex:2.1.28,ex:2.1.29,ex:2.1.30,ex:2.1.31,ex:2.1.32} assume that \(\W\) is a subspace of a vector space \(\V\) over \(\F\) and that \(\T : \V \to \V\) is linear.

\begin{ex}\label{ex:2.1.28}
  Prove that the subspaces \(\set{\zv}\), \(\V\), \(\rg{\T}\), and \(\ns{\T}\) are all \(\T\)-invariant.
\end{ex}

\begin{proof}[\pf{ex:2.1.28}]
  First we show that \(\set{\zv}\) is \(\T\)-invariant.
  By \cref{2.1.2}(a) we know that \(\T(\set{\zv}) = \set{\zv} \subseteq \set{\zv}\), thus by \cref{2.1.15} \(\set{\zv}\) is \(\T\)-invariant.

  Next we show that \(\V\) is \(\T\)-invariant.
  Obviously \(\T(\V) \subseteq \T(\V)\), thus by \cref{2.1.15} \(\V\) is \(\T\)-invariant.

  Next we show that \(\rg{\T}\) is \(\T\)-invariant.
  Since
  \begin{align*}
             & \forall y \in \rg{\T}, y \in \V          &  & (\T : \V \to \V)          \\
    \implies & \forall y \in \rg{\T}, \T(y) \in \rg{\T} &  & \text{(by \cref{2.1.10})} \\
    \implies & \T(\rg{\T}) \subseteq \rg{\T},
  \end{align*}
  by \cref{2.1.15} we know that \(\rg{\T}\) is \(\T\)-invariant.

  Finally we show that \(\ns{\T}\) is \(\T\)-invariant.
  Since
  \begin{align*}
             & \forall x \in \ns{\T}, \T(x) = \zv                 &  & \text{(by \cref{2.1.10})} \\
    \implies & \T(\ns{\T}) \subseteq \set{\zv} \subseteq \ns{\T}, &  & \text{(by \cref{1.3}(a))}
  \end{align*}
  by \cref{2.1.15} we know that \(\ns{\T}\) is \(\T\)-invariant.
\end{proof}

\begin{ex}\label{ex:2.1.29}
  If \(\W\) is \(\T\)-invariant, prove that \(\T_{\W}\) is linear.
\end{ex}

\begin{proof}[\pf{ex:2.1.29}]
  Let \(x, y \in \W\) and let \(c \in \F\).
  Since
  \begin{align*}
             & cx + y \in \W                &  & \text{(by \cref{1.3}(b)(c))} \\
    \implies & \T_{\W}(cx + y) = \T(cx + y) &  & \text{(by \cref{2.1.15})}    \\
             & = c \T(x) + \T(y)            &  & \text{(by \cref{2.1.2}(b))}  \\
             & = c \T_{\W}(x) + \T_{\W}(y), &  & \text{(by \cref{2.1.15})}
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T_{\W}\) is linear.
\end{proof}

\begin{ex}\label{ex:2.1.30}
  Suppose that \(\T\) is a projection on \(\W\) along some subspace \(\W'\).
  Prove that \(\W\) is \(\T\)-invariant and that \(\T_{\W} = \IT[\W]\).
\end{ex}

\begin{proof}[\pf{ex:2.1.30}]
  We have
  \begin{align*}
             & \T \text{ is a projection on } \W \text{ along } \W'                                                                 \\
    \implies & \begin{dcases}
      \V = \W \oplus \W' \\
      \forall x \in \V, \exists (x_1, x_2) \in \W \times \W' : \T(x) = \T(x_1 + x_2) = x_1
    \end{dcases}                                                           &  & \text{(by \cref{2.1.14})} \\
    \implies & \forall x \in \W, \exists (x, \zv) \in \W \times \W' : \T(x) = \T(x + \zv) = x \in \W &  & \text{(by \cref{1.3}(a))} \\
    \implies & \T(\W) \subseteq \W                                                                                                  \\
    \implies & \W \text{ is } \T\text{-invariant}                                                    &  & \text{(by \cref{2.1.15})}
  \end{align*}
  and
  \begin{align*}
             & \forall x \in \W, \T(x) = x                                     \\
    \implies & \forall x \in \W, \T_{\W}(x) = x &  & \text{(by \cref{2.1.15})} \\
    \implies & \T_{\W} = \IT[\W].               &  & \text{(by \cref{2.1.9})}
  \end{align*}
\end{proof}

\begin{ex}\label{ex:2.1.31}
  Suppose that \(\V = \rg{\T} \oplus \W\) and \(\W\) is \(\T\)-invariant.
  (See \cref{1.3.11}.)
  \begin{enumerate}
    \item Prove that \(\W \subseteq \ns{\T}\).
    \item Show that if \(\V\) is finite-dimensional, then \(\W = \ns{\T}\).
    \item Show by example that the conclusion of (b) is not necessarily true if \(\V\) is not finite-dimensional.
  \end{enumerate}
\end{ex}

\begin{proof}[\pf{ex:2.1.31}(a)]
  We have
  \begin{align*}
             & \begin{dcases}
      \V = \rg{\T} \oplus \W \\
      \T(\W) \subseteq \W
    \end{dcases}                               &  & \text{(by \cref{2.1.15})} \\
    \implies & \rg{\T} \cap \T(\W) \subseteq \rg{\T} \cap \W = \set{\zv} &  & \text{(by \cref{1.3.11})} \\
    \implies & \T(\W) = \rg{\T} \cap \T(\W) \subseteq \set{\zv}          &  & \text{(by \cref{2.1.10})} \\
    \implies & \forall x \in \W, \T(x) = \zv                                                            \\
    \implies & \W \subseteq \ns{\T}.                                     &  & \text{(by \cref{2.1.10})}
  \end{align*}
\end{proof}

\begin{proof}[\pf{ex:2.1.31}(b)]
  Since \(\V = \rg{\T} \oplus \W\), by \cref{ex:1.6.29}(b) we know that \(\dim(\V) = \rk{\T} + \dim(\W)\).
  By dimension theorem (\cref{2.3}) we know that \(\ns{\T} = \dim(\V) - \rk{\T} = \dim(\W)\).
  By \cref{ex:2.1.31}(a) we know that \(\W \subseteq \ns{\T}\), thus by \cref{1.11} we have \(\W = \ns{\T}\).
\end{proof}

\begin{proof}[\pf{ex:2.1.31}(c)]
  Let \(\V\) and \(\T\) defined as in \cref{ex:2.1.21}.
  Let \(\W = \set{(0, 0, \dots)}\).
  By \cref{ex:2.1.21}(b) we know that \(\V = \rg{\T} = \rg{\T} \oplus \W\).
  But then we have
  \begin{align*}
             & (1, 0, 0, \dots) \in \V                                                     \\
    \implies & \T(1, 0, 0, \dots) = (0, 0, \dots)        &  & \text{(by \cref{ex:2.1.21})} \\
    \implies & (1, 0, 0, \dots) \in \ns{\T} \setminus \W                                   \\
    \implies & \ns{\T} \neq \W.
  \end{align*}
\end{proof}

\begin{ex}\label{ex:2.1.32}
  Suppose that \(\W\) is \(\T\)-invariant.
  Prove that \(\ns{\T_{\W}} = \ns{\T} \cap \W\) and \(\rg{\T_{\W}} = \T(\W)\).
\end{ex}

\begin{proof}[\pf{ex:2.1.32}]
  First we show that \(\ns{\T_{\W}} = \ns{\T} \cap \W\).
  Since
  \begin{align*}
         & x \in \ns{\T_{\W}}                                         \\
    \iff & \begin{dcases}
      x \in \W \\
      \T_{\W}(x) = \zv
    \end{dcases} &  & \text{(by \cref{2.1.10})} \\
    \iff & \begin{dcases}
      x \in \W \\
      \T(x) = \zv
    \end{dcases} &  & \text{(by \cref{2.1.15})} \\
    \iff & \begin{dcases}
      x \in \W \\
      x \in \ns{\T}
    \end{dcases} &  & \text{(by \cref{2.1.15})} \\
    \iff & x \in \ns{\T} \cap \W,
  \end{align*}
  we know that \(\ns{\T_{\W}} = \ns{\T} \cap \W\).

  Now we show that \(\rg{\T_{\W}} = \T(\W)\).
  This is true since
  \begin{align*}
    \T(\W) & = \T_{\W}(\W)   &  & \text{(by \cref{2.1.15})} \\
           & = \rg{\T_{\W}}. &  & \text{(by \cref{2.1.10})}
  \end{align*}
\end{proof}

\begin{ex}\label{ex:2.1.33}
  Prove \cref{2.2} for the case that \(\beta\) is infinite, that is, \(\rg{\T} = \spn{\set{\T(v) : v \in \beta}}\).
\end{ex}

\begin{proof}[\pf{ex:2.1.33}]
  Clearly we have \(\set{\T(v) : v \in \beta} \subseteq \rg{\T}\).
  By \cref{2.1} we know that \(\rg{\T}\) is a vector space over \(\F\), thus by \cref{1.5} we have
  \[
    \spn{\set{\T(v) : v \in \beta}} \subseteq \rg{\T}.
  \]
  Let \(x \in \V\).
  Since \(\beta\) is a basis for \(\V\) over \(\F\), by \cref{1.6.1} there exists some \(\seq{v}{1,2,,n} \in \beta\) such that \(x \in \spn{\set{\seq{v}{1,2,,n}}}\).
  In particular, there exist some \(\seq{a}{1,2,,n} \in \F\) such that \(x = \sum_{i = 1}^n a_i v_i\).
  Since \(\T\) is linear, by \cref{2.1.2}(d) we know that
  \[
    \T(x) = \T\pa{\sum_{i = 1}^n a_i v_i} = \sum_{i = 1}^n a_i \T(v_i) \in \spn{\set{\T(v) : v \in \beta}}.
  \]
  This means \(\rg{\T} \subseteq \spn{\set{\T(v) : v \in \beta}}\), thus we have \(\rg{\T} = \spn{\set{\T(v) : v \in \beta}}\).
\end{proof}

\begin{ex}\label{ex:2.1.37}
  A function \(\T : \V \to \W\) between vector spaces \(\V\) and \(\W\) over \(\F\) is called \textbf{additive} if \(\T(x + y) = \T(x) + \T(y)\) for all \(x, y \in \V\).
  Prove that if \(\V\) and \(\W\) are vector spaces over the field of rational numbers \(\Q\), then any additive function from \(\V\) into \(\W\) is a linear transformation.
\end{ex}
