\section{Subspaces}\label{sec:1.3}

\begin{defn}\label{1.3.1}
  A subset \(\W\) of a vector space \(\V\) over a field \(\F\) is called a \textbf{subspace} of \(\V\) over \(\F\) if \(\W\) is a vector space over \(\F\) with the operations of addition and scalar multiplication defined on \(\V\).
\end{defn}

\begin{eg}\label{1.3.2}
  In any vector space \(\V\) over \(\F\), note that \(\V\) and \(\set{\zv}\) are subspaces.
  The latter is called the \textbf{zero subspace} of \(\V\) over \(\F\).
\end{eg}

\begin{proof}
  Since \(\V \subseteq \V\) and \(\V\) is a vector space over \(\F\) with the operations of addition and scalar multiplication defined on \(\V\), by \cref{1.3.1} we know that \(\V\) is a subspace of \(\V\) over \(\F\).
  Since \(\zv \in \V\) (by \ref{vs3}), we know that \(\set{\zv} \subseteq \V\).
  Thus by \cref{ex:1.2.11} and \cref{1.3.1} \(\set{\zv}\) is a subspace of \(\V\) over \(\F\).
\end{proof}

\begin{thm}\label{1.3}
  Let \(\V\) be a vector space over \(\F\) and \(\W\) a subset of \(\V\).
  Then \(\W\) is a subspace of \(\V\) over \(\F\) if and only if the following three conditions hold for the operations defined in \(\V\).
  \begin{enumerate}
    \item \(\zv \in \W\).
    \item (\(\W\) is \textbf{closed under addition}.)
          \(x + y \in \W\) whenever \(x \in \W\) and \(y \in \W\).
    \item (\(\W\) is \textbf{closed under scalar multiplication}.)
          \(cx \in \W\) whenever \(c \in \F\) and \(x \in \W\).
  \end{enumerate}
\end{thm}

\begin{proof}
  If \(\W\) is a subspace of \(\V\) over \(\F\), then \(\W\) is a vector space over \(\F\) with the operations of addition and scalar multiplication defined on \(\V\).
  Hence conditions (b) and (c) hold, and there exists a vector \(\zv' \in \W\) such that \(x + \zv' = x\) for each \(x \in \W\).
  But also \(x + \zv = x\), and thus \(\zv' = \zv\) by \cref{1.1}.
  So condition (a) holds.

  Since properties \ref{vs1}, \ref{vs2}, \ref{vs5}, \ref{vs6}, \ref{vs7}, and \ref{vs8} hold for all vectors in the vector space, these properties automatically hold for the vectors in any subset.
  Thus if conditions (a), (b), and (c) hold, then \(\W\) is a subspace of \(\V\) over \(\F\) if the additive inverse of each vector in \(\W\) lies in \(\W\).
  But if \(x \in W\), then \(\p{-1} x \in \W\) by condition (c), and \(-x = \p{-1} x\) by \cref{1.2}.
  Hence \(\W\) is a subspace of \(\V\) over \(\F\).
\end{proof}

\begin{defn}\label{1.3.3}
  The \textbf{transpose} \(\tp{A}\) of an \(m \times n\) matrix \(A\) is the \(n \times m\) matrix obtained from \(A\) by interchanging the rows with the columns;
  that is, \(\p{\tp{A}}_{i j} = A_{j i}\).
\end{defn}

\begin{defn}\label{1.3.4}
  A \textbf{symmetric matrix} is a matrix \(A\) such that \(\tp{A} = A\).
  Clearly, a symmetric matrix must be square.
\end{defn}

\begin{eg}\label{1.3.5}
  The set \(\W\) of all symmetric matrices in \(\ms{n}{n}{\F}\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Observe that
  \begin{itemize}
    \item The zero matrix is equal to its transpose and hence belongs to \(\W\).
    \item If \(A \in \W\) and \(B \in \W\), then \(\tp{A} = A\) and \(\tp{B} = B\).
          Thus by \cref{ex:1.3.3} \(\tp{\p{A + B}} = \tp{A} + \tp{B} = A + B\), so that \(A + B \in \W\).
    \item If \(A \in \W\), then \(\tp{A} = A\).
          So for any \(a \in \F\), we have \(\tp{\p{aA}} = a\tp{A} = aA\) by \cref{ex:1.3.3}
          Thus \(aA \in W\).
  \end{itemize}
  Thus by \cref{1.3} \(\W\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{proof}

\begin{eg}\label{1.3.6}
  Let \(n\) be a nonnegative integer, and let \(\ps[n]{\F}\) consist of all polynomials in \(\ps{\F}\) having degree less than or equal to \(n\).
  Then \(\ps[n]{\F}\) is a subspace of \(\ps{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Since the zero polynomial has degree \(-1\), it is in \(\ps[n]{\F}\).
  Moreover, the sum of two polynomials with degrees less than or equal to \(n\) is another polynomial of degree less than or equal to \(n\), and the product of a scalar and a polynomial of degree less than or equal to \(n\) is a polynomial of degree less than or equal to \(n\).
  So \(\ps[n]{\F}\) is closed under addition and scalar multiplication.
  It therefore follows from \cref{1.3} that \(\ps[n]{\F}\) is a subspace of \(\ps{\F}\) over \(\F\).
\end{proof}

\begin{eg}\label{1.3.7}
  Let \(\cfs{\R}\) denote the set of all continuous real-valued functions defined on \(\R\).
  Clearly \(\cfs{\R}\) is a subset of the vector space \(\fs{\R}{\R}\) defined in \cref{1.2.10} of \cref{sec:1.2}.
  We claim that \(\cfs{\R}\) is a subspace of \(\fs{\R}{\R}\) over \(\R\).
\end{eg}

\begin{proof}
  First note that the zero of \(\fs{\R}{\R}\) is the constant function defined by \(f\p{t} = 0\) for all \(t \in \R\).
  Since constant functions are continuous, we have \(f \in \cfs{\R}\).
  Moreover, the sum of two continuous functions is continuous, and the product of a real number and a continuous function is continuous.
  So \(\cfs{\R}\) is closed under addition and scalar multiplication and hence is a subspace of \(\fs{\R}{\R}\) over \(\R\) by \cref{1.3}.
\end{proof}

\begin{eg}\label{1.3.8}
  An \(n \times n\) matrix \(M\) is called a \textbf{diagonal matrix} if \(M_{i j} = 0\) whenever \(i \neq j\), that is, if all its nondiagonal entries are zero.
  Then the set of diagonal matrices is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Clearly the zero matrix is a diagonal matrix because all of its entries are \(0\).
  Moreover, if \(A\) and \(B\) are diagonal \(n \times n\) matrices, then whenever \(i \neq j\),
  \[
    \p{A + B}_{i j} = A_{i j} + B_{i j} = 0 + 0 = 0 \quad \text{and} \quad \p{cA}_{i j} = cA_{i j} = c0 = 0
  \]
  for any scalar \(c \in \F\).
  Hence \(A + B\) and \(cA\) are diagonal matrices for any scalar \(c \in \F\).
  Therefore the set of diagonal matrices is a subspace of \(\ms{n}{n}{\F}\) over \(\F\) by \cref{1.3}.
\end{proof}

\begin{eg}\label{1.3.9}
  The \textbf{trace} of an \(n \times n\) matrix \(M\), denoted \(\tr{M}\), is the sum of the diagonal entries of \(M\);
  that is,
  \[
    \tr{M} = M_{1 1} + M_{2 2} + \dots + M_{n n}.
  \]
  The set \(\W\) of \(n \times n\) matrices having trace equal to \(0\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Clearly we have \(\W \subseteq \ms{n}{n}{\F}\), \(\tr{\zm} = 0\) and \(\zm \in \W\).
  Moreover, if \(A, B \in \W\), then
  \begin{align*}
    \tr{A + B} & = \sum_{i = 1}^{n} \p{A + B}_{i i}                    &  & \text{(by \cref{1.3.9})}  \\
               & = \sum_{i = 1}^{n} \p{A_{i i} + B_{i i}}              &  & \text{(by \cref{1.2.9})}  \\
               & = \sum_{i = 1}^{n} A_{i i} + \sum_{i = 1}^{n} B_{i i} &  & (A_{i i}, B_{i i} \in \F) \\
               & = 0                                                   &  & (A, B \in \W)
  \end{align*}
  and
  \begin{align*}
    \tr{cA} & = \sum_{i = 1}^{n} \p{cA}_{i i} &  & \text{(by \cref{1.3.9})} \\
            & = \sum_{i = 1}^{n} cA_{i i}     &  & \text{(by \cref{1.2.9})} \\
            & = c \sum_{i = 1}^{n} A_{i i}    &  & (c, A_{i i} \in \F)      \\
            & = c0                            &  & (A \in \W)               \\
            & = 0                             &  & (c \in \F)
  \end{align*}
  for any scalar \(c \in \F\).
  Therefore \(\W\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\) by \cref{1.3}.
\end{proof}

\begin{thm}\label{1.4}
  Any intersection of subspaces of a vector space \(\V\) is a subspace of \(\V\).
\end{thm}

\begin{proof}
  Let \(\cvs\) be a collection of subspaces of \(\V\) over \(\F\), and let \(\W\) denote the intersection of the subspaces in \(\cvs\).
  Since every subspace contains the zero vector, \(\zv \in \W\).
  Let \(a \in \F\) and \(x, y \in \W\).
  Then \(x\) and \(y\) are contained in each subspace in \(\cvs\).
  Because each subspace in \(\cvs\) is closed under addition and scalar multiplication, it follows that \(x + y\) and \(ax\) are contained in each subspace in \(\cvs\).
  Hence \(x + y\) and \(ax\) are also contained in \(\W\), so that \(\W\) is a subspace of \(\V\) over \(\F\) by \cref{1.3}.
\end{proof}

\exercisesection

\setcounter{ex}{2}
\begin{ex}\label{ex:1.3.3}
  Prove that \(\tp{\p{aA + bB}} = a\tp{A} + b\tp{B}\) for any \(A, B \in \ms{m}{n}{\F}\) and any \(a, b \in \F\).
\end{ex}

\begin{proof}
  Let \(i = 1, \dots, n\) and \(j = 1, \dots, m\).
  Since
  \begin{align*}
    \p{a\tp{A} + b\tp{B}}_{i j} & = a\p{\tp{A}}_{i j} + b\p{\tp{B}}_{i j} &  & \text{(by \cref{1.2.9})} \\
                                & = aA_{j i} + bB_{j i}                   &  & \text{(by \cref{1.3.3})} \\
                                & = \p{aA}_{j i} + \p{bB}_{j i}           &  & \text{(by \cref{1.2.9})} \\
                                & = \p{aA + bB}_{j i}                     &  & \text{(by \cref{1.2.9})} \\
                                & = \tp{\p{aA + bB}}_{i j},               &  & \text{(by \cref{1.3.3})}
  \end{align*}
  by \cref{1.2.7} we know that \(\tp{\p{aA + bB}} = a\tp{A} + b\tp{B}\).
\end{proof}

\begin{ex}\label{ex:1.3.4}
  Prove that \(\tp{\p{\tp{A}}} = A\) for each \(A \in \MS\).
\end{ex}

\begin{proof}
  Let \(i = 1, \dots, m\) and \(j = 1, \dots, n\).
  Since
  \begin{align*}
    A_{i j} & = \p{\tp{A}}_{j i}           &  & \text{(by \cref{1.3.3})} \\
            & = \p{\tp{\p{\tp{A}}}}_{i j}, &  & \text{(by \cref{1.3.3})}
  \end{align*}
  by \cref{1.2.8} we know that \(\tp{\p{\tp{A}}} = A\).
\end{proof}

\begin{ex}\label{ex:1.3.5}
  Prove that \(A + \tp{A}\) is symmetric for any square matrix \(A \in \ms{n}{n}{\F}\).
\end{ex}

\begin{proof}
  Since
  \begin{align*}
    A + \tp{A} & = \tp{\p{\tp{A}}} + \tp{A} &  & \text{(by \cref{ex:1.3.4})} \\
               & = \tp{\p{\tp{A} + A}}      &  & \text{(by \cref{ex:1.3.3})} \\
               & = \tp{\p{A + \tp{A}}},     &  & \text{(by \cref{1.2.9})}
  \end{align*}
  by \cref{1.3.4} \(A + \tp{A}\) is symmetric.
\end{proof}

\begin{ex}\label{ex:1.3.6}
  Prove that \(\tr{aA + bB} = a\tr{A} + b\tr{B}\) for any \(A, B \in \ms{n}{n}{\F}\).
\end{ex}

\begin{proof}
  We have
  \begin{align*}
    \tr{aA + bB} & = \sum_{i = 1}^{n} (aA + bB)_{i i}                        &  & \text{(by \cref{1.3.9})}    \\
                 & = \sum_{i = 1}^{n} \p{aA_{i i} + bB_{i i}}                &  & \text{(by \cref{1.2.9})}    \\
                 & = a \sum_{i = 1}^{n} A_{i i} + b \sum_{i = 1}^{n} B_{i i} &  & (aA_{i i}, bB_{i i} \in \F) \\
                 & = a\tr{A} + b\tr{B}.                                      &  & \text{(by \cref{1.3.9})}
  \end{align*}
\end{proof}

\begin{ex}\label{ex:1.3.7}
  Prove that diagonal matrices are symmetric matrices.
\end{ex}

\begin{proof}
  Let \(A \in \ms{n}{n}{\F}\) be a diagonal matrices and let \(i, j = 1, \dots, n\).
  Then we have
  \begin{align*}
             & \begin{dcases}
      A_{i j} = A_{j i} = 0 & \text{if } i \neq j \\
      A_{i i} = A_{i i}     & \text{otherwise}
    \end{dcases}           &  & \text{(by \cref{1.3.8})} \\
    \implies & A_{i j} = A_{j i} = \p{\tp{A}}_{i j} &  & \text{(by \cref{1.3.3})} \\
    \implies & A = \tp{A}                           &  & \text{(by \cref{1.2.8})}
  \end{align*}
  and thus by \cref{1.3.4} diagonal matrices are symmetric.
\end{proof}

\setcounter{ex}{11}
\begin{ex}\label{ex:1.3.12}
  An \(m \times n\) matrix \(A\) is called \textbf{upper triangular} if all entries lying below the diagonal entries are zero, that is, if \(A_{i j} = 0\) whenever \(i > j\).
  Prove that the upper triangular matrices form a subspace of \(\MS\) over \(\F\).
\end{ex}

\begin{proof}
  Clearly the zero matrix is a upper triangular matrix because all of its entries are \(0\).
  Moreover, if \(A\) and \(B\) are upper triangular \(m \times n\) matrices, then whenever \(i > j\),
  \[
    \p{A + B}_{i j} = A_{i j} + B_{i j} = 0 + 0 = 0 \quad \text{and} \quad \p{cA}_{i j} = cA_{i j} = c0 = 0
  \]
  for any scalar \(c \in \F\).
  Hence \(A + B\) and \(cA\) are upper triangular matrices for any scalar \(c \in \F\).
  Therefore the set of upper triangular matrices is a subspace of \(\MS\) over \(\F\) by \cref{1.3}.
\end{proof}

\begin{ex}\label{ex:1.3.13}
  Let \(S\) be a nonempty set and \(\F\) a field.
  Prove that for any \(s_{0} \in S\), \(\W = \set{f \in \FS : f\p{s_{0}} = 0}\), is a subspace of \(\FS\) over \(\F\).
\end{ex}

\begin{proof}
  Clearly we have \(\W \subseteq \FS\) and the zero function \(\zv \in \W\) because \(\zv\p{s_{0}} = 0\).
  Moreover, if \(f, g \in \W\), then
  \begin{align*}
    \p{f + g}\p{s_{0}} & = f\p{s_{0}} + g\p{s_{0}} &  & \text{(by \cref{1.2.10})} \\
                       & = 0 + 0                   &  & (f, g \in \W)             \\
                       & = 0
  \end{align*}
  and
  \begin{align*}
    \p{cf}\p{s_{0}} & = cf\p{s_0} &  & \text{(by \cref{1.2.10})} \\
                    & = c0        &  & (f \in \W)                \\
                    & = 0         &  & (c \in \F)
  \end{align*}
  for any scalar \(c \in \F\).
  Hence \(f + g, cf \in \W\) for any scalar \(c \in \F\).
  Therefore \(\W\) is a subspace of \(\FS\) over \(\F\) by \cref{1.3}.
\end{proof}

\setcounter{ex}{15}
\begin{ex}\label{ex:1.3.16}
  Let \(\cfs[n]{\R}\) denote the set of all real-valued functions defined on the real line that have a continuous \(n\)th derivative.
  Prove that \(\cfs[n]{\R}\) is a subspace of \(\fs{\R}{\R}\).
\end{ex}

\begin{proof}
  First note that the zero of \(\fs{\R}{\R}\) is the constant function defined by \(\zv\p{x} = 0\) for all \(x \in \R\).
  Since constant functions has continuous \(n\)th derivative, we have \(\zv \in \cfs[n]{\R}\).
  Moreover, if \(f, g \in \W\), then
  \[
    f^{\p{n}} + g^{\p{n}} = \p{f + g}^{\p{n}} \quad \text{and} \quad cf^{\p{n}} = \p{cf}^{\p{n}}
  \]
  for any scalar \(c \in \F\).
  Hence \(f + g, cf \in \cfs[n]{\R}\) for any scalar \(c \in \F\).
  Therefore \(\cfs[n]{\R}\) is a subspace of \(\fs{\R}{\R}\) over \(\R\) by \cref{1.3}.
\end{proof}

\begin{ex}\label{ex:1.3.17}
  Prove that a subset \(\W\) of a vector space \(\V\) is a subspace of \(\V\) if and only if \(\W \neq \varnothing\), and, whenever \(a \in \F\) and \(x, y \in \W\), then \(ax \in \W\) and \(x + y \in \W\).
\end{ex}

\begin{proof}
  Since
  \begin{align*}
             & \begin{dcases}
      \W \neq \varnothing               \\
      \forall x, y \in \W, x + y \in \W \\
      \forall (x, a) \in \W \times \F, ax \in \W
    \end{dcases}                                 \\
    \implies & \begin{dcases}
      \exists x \in \W                  \\
      \forall x, y \in \W, x + y \in \W \\
      \forall (x, a) \in \W \times \F, ax \in \W
    \end{dcases}                                 \\
    \implies & \begin{dcases}
      0x = \zv \in \W                   \\
      \forall x, y \in \W, x + y \in \W \\
      \forall (x, a) \in \W \times \F, ax \in \W
    \end{dcases}, &  & \text{(by \cref{1.2}(a))}
  \end{align*}
  by \cref{1.3} we know that
  \[
    \begin{dcases}
      \zv \in \W                        \\
      \forall x, y \in \W, x + y \in \W \\
      \forall (x, a) \in \W \times \F, ax \in \W
    \end{dcases} \iff \begin{dcases}
      W \neq \varnothing                \\
      \forall x, y \in \W, x + y \in \W \\
      \forall (x, a) \in \W \times \F, ax \in \W
    \end{dcases}.
  \]
\end{proof}

\begin{ex}\label{ex:1.3.18}
  Prove that a subset \(\W\) of a vector space \(\V\) is a subspace of \(\V\) if and only if \(0 \in \W\) and \(ax + y \in \W\) whenever \(a \in \F\) and \(x, y \in \W\).
\end{ex}

\begin{proof}
  Since
  \[
    \begin{dcases}
      \zv \in \W                        \\
      \forall x, y \in \W, x + y \in \W \\
      \forall (x, a) \in \W \times \F, ax \in \W
    \end{dcases} \implies \begin{dcases}
      \zv \in \W \\
      \begin{dcases}
        \forall x, y \in \W \\
        \forall a \in \F
      \end{dcases}, ax + y \in \W
    \end{dcases}
  \]
  and
  \[
    \begin{dcases}
      \zv \in \W \\
      \begin{dcases}
        \forall x, y \in \W \\
        \forall a \in \F
      \end{dcases}, ax + y \in \W
    \end{dcases} \implies \begin{dcases}
      \zv \in \W                                                      \\
      \forall x, y \in \W, x + y \in \W          & \text{if } a = 1   \\
      \forall (x, a) \in \W \times \F, ax \in \W & \text{if } y = \zv
    \end{dcases},
  \]
  by \cref{1.3} we know that \cref{ex:1.3.18} is true.
\end{proof}

\begin{ex}\label{ex:1.3.19}
  Let \(\W_{1}\) and \(\W_{2}\) be subspaces of a vector space \(\V\) over \(\F\).
  Prove that \(\W_{1} \cup \W_{2}\) is a subspace of \(\V\) over \(\F\) if and only if \(\W_{1} \subseteq \W_{2}\) or \(\W_{2} \subseteq \W_{1}\).
\end{ex}

\begin{proof}
  First suppose that \(\W_{1} \cup \W_{2}\) is a subspace of \(\V\) over \(\F\).
  Let \(x \in \W_{1}\) and \(y \in \W_{2}\).
  Then we have
  \begin{align*}
             & \begin{dcases}
      \W_{1} \subseteq \W_{1} \cup \W_{2} \\
      \W_{2} \subseteq \W_{1} \cup \W_{2}
    \end{dcases}                                                                         \\
    \implies & x + y \in \W_{1} \cup \W_{2}                                     &  & \text{(by \cref{1.3}(b))}    \\
    \implies & \p{x + y \in \W_{1}} \lor \p{x + y \in \W_{2}}                                                     \\
    \implies & \p{\p{-x} + x + y \in \W_{1}} \lor \p{x + y + \p{-y} \in \W_{2}} &  & \text{(by \cref{1.3}(b)(c))} \\
    \implies & \p{y \in \W_{1}} \lor \p{x \in \W_{2}}                           &  & \text{(by \ref{vs4})}        \\
    \implies & \p{\W_{2} \subseteq \W_{1}} \lor \p{\W_{1} \subseteq \W_{2}}.
  \end{align*}

  Now suppose that \(\W_{1} \subseteq \W_{2}\) or \(\W_{2} \subseteq \W_{1}\).
  Then we have
  \begin{align*}
             & \p{\W_{2} \subseteq \W_{1}} \lor \p{\W_{1} \subseteq \W_{2}}          \\
    \implies & \p{\W_{1} \cup \W_{2} = \W_{1}} \lor \p{\W_{1} \cup \W_{2} = \W_{2}}.
  \end{align*}
  Thus \cref{ex:1.3.19} is true.
\end{proof}

\begin{ex}\label{ex:1.3.20}
  Prove that if \(\W\) is a subspace of a vector space \(\V\) over \(\F\) and \(\seq{w}{1,2,,n}{,} \in \W\), then \(\seq{a,w}{1,2,,n}{+} \in \W\) for any \(\seq{a}{1,2,,n}{,} \in \F\).
\end{ex}

\begin{proof}
  We use induction on \(n\).
  For \(n = 1\), we have \(\seq{a,w}{1}{,} \in \W\) by \cref{1.3}(c).
  Thus the base case holds.
  Suppose inductively that \(\seq{a,w}{1,2,,n}{+} = \sum_{i = 1}^{n} a_{i} w_{i} \in \W\) for some \(n \geq 1\).
  Then for \(n + 1\), we have
  \begin{align*}
             & \begin{dcases}
      \sum_{i = 1}^{n} a_{i} w_{i} \in \W \\
      w_{n + 1} \in \W                    \\
      a_{n + 1} \in \F
    \end{dcases}                                          &  & \text{(by induction hypothesis)} \\
             & \begin{dcases}
      \sum_{i = 1}^{n} a_{i} w_{i} \in \W \\
      a_{n + 1} w_{n + 1} \in \W
    \end{dcases}                                          &  & \text{(by \cref{1.3}(c))}        \\
    \implies & \seq{a,w}{1,2,,n,n + 1}{+}                                                                                \\
             & = \p{\sum_{i = 1}^{n} a_{i} w_{i}} + \p{a_{n + 1} w_{n + 1}} \in \W &  & \text{(by \cref{1.3}(b))}
  \end{align*}
  and this closes the induction.
\end{proof}

\begin{ex}\label{ex:1.3.21}
  Show that the set of convergent sequences \(\set{a_{n}}\) (i.e., those for which \(\lim_{n \to \infty} a_{n}\) exists) is a subspace of the vector space \(\V\) over \(\F\) in \cref{1.2.13} of \cref{sec:1.2}.
\end{ex}

\begin{proof}
  Clearly the zero sequence converges to \(0\) because all of its entries are \(0\).
  Moreover, if \(\set{a_{n}}, \set{b_{n}}\) are convergent sequences, then
  \[
    \lim_{n \to \infty} a_{n} + b_{n} = \lim_{n \to \infty} a_{n} + \lim_{n \to \infty} b_{n} \quad \text{and} \quad \lim_{n \to \infty} ca_{n} = c \p{\lim_{n \to \infty} a_{n}}
  \]
  for any scalar \(c \in \F\).
  Hence \(\set{a_{n}} + \set{b_{n}}\) and \(c\set{a_{n}}\) are convergent sequences for any scalar \(c \in \F\).
  Therefore the set of convergent sequences is a subspace of \(\V\) over \(\F\) by \cref{1.3}.
\end{proof}

\begin{defn}\label{1.3.10}
  If \(S_{1}\) and \(S_{2}\) are nonempty subsets of a vector space \(\V\), then the \textbf{sum} of \(S_{1}\) and \(S_{2}\), denoted \(S_{1} + S_{2}\), is the set \(\set{x + y : x \in S_{1} \text{ and } y \in S_{2}}\).
\end{defn}

\begin{defn}\label{1.3.11}
  A vector space \(\V\) is called the \textbf{direct sum} of \(\W_{1}\) and \(\W_{2}\) if \(\W_{1}\) and \(\W_{2}\) are subspaces of \(\V\) such that \(\W_{1} \cap \W_{2} = \set{0}\) and \(\W_{1} + \W_{2} = \V\).
  We denote that \(\V\) is the direct sum of \(\W_{1}\) and \(\W_{2}\) by writing \(\V = \W_{1} \oplus \W_{2}\).
\end{defn}
