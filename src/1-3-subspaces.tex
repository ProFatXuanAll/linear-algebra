\section{Subspaces}\label{sec:1.3}

\begin{defn}\label{1.3.1}
  A subset \(\W\) of a vector space \(\V\) over a field \(\F\) is called a \textbf{subspace} of \(\V\) if \(\W\) is a vector space over \(\F\) with the operations of addition and scalar multiplication defined on \(\V\).
\end{defn}

\begin{eg}\label{1.3.2}
  In any vector space \(\V\), note that \(\V\) and \(\set{\zv}\) are subspaces.
  The latter is called the \textbf{zero subspace} of \(\V\).
\end{eg}

\begin{proof}
  Since \(\V \subseteq \V\) and \(\V\) is a vector space over \(\F\) with the operations of addition and scalar multiplication defined on \(\V\), by \cref{1.3.1} we know that \(\V\) is a subspace of \(\V\).
  Since \(\zv \in \V\) (by \ref{vs3}), we know that \(\set{\zv} \subseteq \V\).
  Thus by \cref{ex:1.2.11} and \cref{1.3.1} \(\set{\zv}\) is a subspace of \(\V\).
\end{proof}

\begin{thm}\label{1.3}
  Let \(\V\) be a vector space and \(\W\) a subset of \(\V\).
  Then \(\W\) is a subspace of \(\V\) if and only if the following three conditions hold for the operations defined in \(\V\).
  \begin{enumerate}
    \item \(\zv \in \W\).
    \item (\(\W\) is \textbf{closed under addition}.)
          \(x + y \in \W\) whenever \(x \in \W\) and \(y \in \W\).
    \item (\(\W\) is \textbf{closed under scalar multiplication}.)
          \(cx \in \W\) whenever \(c \in \F\) and \(x \in \W\).
  \end{enumerate}
\end{thm}

\begin{proof}
  If \(\W\) is a subspace of \(\V\), then \(\W\) is a vector space with the operations of addition and scalar multiplication defined on \(\V\).
  Hence conditions (b) and (c) hold, and there exists a vector \(\zv' \in \W\) such that \(x + \zv' = x\) for each \(x \in \W\).
  But also \(x + \zv = x\), and thus \(\zv' = \zv\) by \cref{1.1}.
  So condition (a) holds.

  Since properties \ref{vs1}, \ref{vs2}, \ref{vs5}, \ref{vs6}, \ref{vs7}, and \ref{vs8} hold for all vectors in the vector space, these properties automatically hold for the vectors in any subset.
  Thus if conditions (a), (b), and (c) hold, then \(\W\) is a subspace of \(\V\) if the additive inverse of each vector in \(\W\) lies in \(\W\).
  But if \(x \in W\), then \(\p{-1} x \in \W\) by condition (c), and \(-x = \p{-1} x\) by \cref{1.2}.
  Hence \(\W\) is a subspace of \(\V\).
\end{proof}

\begin{defn}\label{1.3.3}
  The \textbf{transpose} \(\tp{A}\) of an \(m \times n\) matrix \(A\) is the \(n \times m\) matrix obtained from \(A\) by interchanging the rows with the columns;
  that is, \(\p{\tp{A}}_{i j} = A_{j i}\).
\end{defn}

\begin{defn}\label{1.3.4}
  A \textbf{symmetric matrix} is a matrix \(A\) such that \(\tp{A} = A\).
  Clearly, a symmetric matrix must be square.
\end{defn}

\begin{eg}\label{1.3.5}
  The set \(\W\) of all symmetric matrices in \(\ms{n}{n}{\F}\) is a subspace of \(\ms{n}{n}{\F}\).
\end{eg}

\begin{proof}
  Observe that
  \begin{itemize}
    \item The zero matrix is equal to its transpose and hence belongs to \(\W\).
    \item If \(A \in \W\) and \(B \in \W\), then \(\tp{A} = A\) and \(\tp{B} = B\).
          Thus by \cref{ex:1.3.3} \(\tp{\p{A + B}} = \tp{A} + \tp{B} = A + B\), so that \(A + B \in \W\).
    \item If \(A \in \W\), then \(\tp{A} = A\).
          So for any \(a \in \F\), we have \(\tp{\p{aA}} = a\tp{A} = aA\) by \cref{ex:1.3.3}
          Thus \(aA \in W\).
  \end{itemize}
  Thus by \cref{1.3} \(\W\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{proof}

\begin{eg}\label{1.3.6}
  Let \(n\) be a nonnegative integer, and let \(\ps[n]{\F}\) consist of all polynomials in \(\ps{\F}\) having degree less than or equal to \(n\).
  Then \(\ps[n]{\F}\) is a subspace of \(\ps{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Since the zero polynomial has degree \(-1\), it is in \(\ps[n]{\F}\).
  Moreover, the sum of two polynomials with degrees less than or equal to \(n\) is another polynomial of degree less than or equal to \(n\), and the product of a scalar and a polynomial of degree less than or equal to \(n\) is a polynomial of degree less than or equal to \(n\).
  So \(\ps[n]{\F}\) is closed under addition and scalar multiplication.
  It therefore follows from \cref{1.3} that \(\ps[n]{\F}\) is a subspace of \(\ps{\F}\) over \(\F\).
\end{proof}

\begin{eg}\label{1.3.7}
  Let \(\cfs{\R}\) denote the set of all continuous real-valued functions defined on \(\R\).
  Clearly \(\cfs{\R}\) is a subset of the vector space \(\fs{\R}{\R}\) defined in \cref{1.2.10} of \cref{sec:1.2}.
  We claim that \(\cfs{\R}\) is a subspace of \(\fs{\R}{\R}\) over \(\R\).
\end{eg}

\begin{proof}
  First note that the zero of \(\fs{\R}{\R}\) is the constant function defined by \(f\p{t} = 0\) for all \(t \in \R\).
  Since constant functions are continuous, we have \(f \in \cfs{\R}\).
  Moreover, the sum of two continuous functions is continuous, and the product of a real number and a continuous function is continuous.
  So \(\cfs{\R}\) is closed under addition and scalar multiplication and hence is a subspace of \(\fs{\R}{\R}\) over \(\R\) by \cref{1.3}.
\end{proof}

\begin{eg}\label{1.3.8}
  An \(n \times n\) matrix \(M\) is called a \textbf{diagonal matrix} if \(M_{i j} = 0\) whenever \(i \neq j\), that is, if all its nondiagonal entries are zero.
  Then the set of diagonal matrices is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Clearly the zero matrix is a diagonal matrix because all of its entries are \(0\).
  Moreover, if \(A\) and \(B\) are diagonal \(n \times n\) matrices, then whenever \(i \neq j\),
  \[
    \p{A + B}_{i j} = A_{i j} + B_{i j} = 0 + 0 = 0 \quad \text{and} \quad \p{cA}_{i j} = cA_{i j} = c0 = 0
  \]
  for any scalar \(c \in \F\).
  Hence \(A + B\) and \(cA\) are diagonal matrices for any scalar \(c \in \F\).
  Therefore the set of diagonal matrices is a subspace of \(\ms{n}{n}{\F}\) over \(\F\) by \cref{1.3}.
\end{proof}

\begin{eg}\label{1.3.9}
  The \textbf{trace} of an \(n \times n\) matrix \(M\), denoted \(\tr{M}\), is the sum of the diagonal entries of \(M\);
  that is,
  \[
    \tr{M} = M_{1 1} + M_{2 2} + \dots + M_{n n}.
  \]
  The set \(\W\) of \(n \times n\) matrices having trace equal to \(0\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\).
\end{eg}

\begin{proof}
  Clearly we have \(\W \subseteq \ms{n}{n}{\F}\), \(\tr{\zm} = 0\) and \(\zm \in \W\).
  Moreover, if \(A, B \in \W\), then
  \begin{align*}
    \tr{A + B} & = \p{A + B}_{1 1} + \p{A + B}_{2 2} + \dots + \p{A + B}_{n n}               &  & \text{(by \cref{1.3.9})}  \\
               & = A_{1 1} + B_{1 1} + A_{2 2} + B_{2 2} + \dots + A_{n n} + B_{n n}         &  & \text{(by \cref{1.2.9})}  \\
               & = A_{1 1} + A_{2 2} + \dots + A_{n n} + B_{1 1} + B_{2 2} + \dots + B_{n n} &  & (A_{i i}, B_{i i} \in \F) \\
               & = 0                                                                         &  & (A, B \in \W)
  \end{align*}
  and
  \begin{align*}
    \tr{cA} & = \p{cA}_{1 1} + \p{cA}_{2 2} + \dots + \p{cA}_{n n} &  & \text{(by \cref{1.3.9})} \\
            & = cA_{1 1} + cA_{2 2} + \dots + cA_{n n}             &  & \text{(by \cref{1.2.9})} \\
            & = c\p{A_{1 1} + A_{2 2} + A_{n n}}                   &  & (c, A_{i i} \in \F)      \\
            & = c0                                                 &  & (A \in \W)               \\
            & = 0                                                  &  & (c \in \F)
  \end{align*}
  for any scalar \(c \in \F\).
  Therefore \(\W\) is a subspace of \(\ms{n}{n}{\F}\) over \(\F\) by \cref{1.3}.
\end{proof}

\exercisesection

\setcounter{ex}{2}
\begin{ex}\label{ex:1.3.3}
  Prove that \(\tp{\p{aA + bB}} = a\tp{A} + b\tp{B}\) for any \(A, B \in \ms{m}{n}{\F}\) and any \(a, b \in \F\).
\end{ex}

\begin{proof}
  Since
  \begin{align*}
    \tp{\p{aA + bB}}_{i j} & = \p{aA + bB}_{j i}                     &  & \text{(by \cref{1.3.3})} \\
                           & = \p{aA}_{j i} + \p{bB}_{j i}           &  & \text{(by \cref{1.2.9})} \\
                           & = aA_{j i} + bB_{j i}                   &  & \text{(by \cref{1.2.9})} \\
                           & = a\p{\tp{A}}_{i j} + b\p{\tp{B}}_{i j} &  & \text{(by \cref{1.3.3})} \\
                           & = \p{a\tp{A} + b\tp{B}}_{i j},          &  & \text{(by \cref{1.2.9})}
  \end{align*}
  by \cref{1.2.7} we know that \(\tp{\p{aA + bB}} = a\tp{A} + b\tp{B}\).
\end{proof}