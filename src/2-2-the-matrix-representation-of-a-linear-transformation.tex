\section{The Matrix Representation of a Linear Transformation}\label{sec:2.2}

\begin{note}
  In \cref{sec:2.2}, we embark on one of the most useful approaches to the analysis of a linear transformation on a finite-dimensional vector space:
  the representation of a linear transformation by a matrix.
  In fact, we develop a one-to-one correspondence between matrices and linear transformations that allows us to utilize properties of one to study properties of the other.
\end{note}

\begin{defn}\label{2.2.1}
  Let \(\V\) be a finite-dimensional vector space over \(\F\).
  An \textbf{ordered basis} for \(\V\) over \(\F\) is a basis for \(\V\) over \(\F\) endowed with a specific order;
  that is, an ordered basis for \(\V\) over \(\F\) is a finite sequence of linearly independent vectors in \(\V\) that generates \(\V\).
\end{defn}

\begin{defn}\label{2.2.2}
  For the vector space \(\vs{F}^n\), we call \(\set{\seq{e}{1,2,,n}}\) the \textbf{standard ordered basis} for \(\vs{F}^n\) over \(\F\).
  Similarly, for the vector space \(\ps[n]{\F}\), we call \(\set{1, x, \dots, x^n}\) the \textbf{standard ordered basis} for \(\ps[n]{\F}\) over \(\F\).
\end{defn}

\begin{defn}\label{2.2.3}
  Let \(\beta = \set{\seq{u}{1,2,,n}}\) be an ordered basis for a finite-dimensional vector space \(\V\) over \(\F\).
  For \(x \in \V\), let \(\seq{a}{1,2,,n} \in \F\) be the unique scalars such that
  \[
    x = \sum_{i = 1}^n a_i u_i.
  \]
  We define the \textbf{coordinate vector of \(x\) relative to \(\beta\)}, denoted \([x]_{\beta}\), by
  \[
    [x]_{\beta} = \begin{pmatrix}
      a_1    \\
      a_2    \\
      \vdots \\
      a_n
    \end{pmatrix}.
  \]
\end{defn}

\begin{defn}\label{2.2.4}
  Suppose that \(\V\) and \(\W\) are finite-dimensional vector spaces over \(\F\) with ordered bases \(\beta = \set{\seq{v}{1,2,,n}}\) and \(\gamma = \set{\seq{w}{1,2,,m}}\) over \(\F\), respectively.
  Let \(\T : \V \to \W\) be linear.
  Then for each \(j\), \(1 \leq j \leq n\), there exist unique scalars \(a_{i j} \in \F\), \(1 \leq i \leq m\), such that
  \[
    \T(v_j) = \sum_{i = 1}^m a_{i j} w_i \quad \text{for } 1 \leq j \leq n.
  \]
  We call the \(m \times n\) matrix \(A\) defined by \(A_{i j} = a_{i j}\) the \textbf{matrix representation of \(\T\) in the ordered bases \(\beta\) and \(\gamma\)} and write \(A = [\T]_{\beta}^{\gamma}\).
  If \(\V = \W\) and \(\beta = \gamma\), then we write \(A = [\T]_{\beta}\).
\end{defn}

\begin{note}
  Notice that the \(j\)th column of \(A\) is simply \([\T(v_j)]_{\gamma}\).
  Also observe that if \(\U : \V \to \W\) is a linear transformation such that \([\U]_{\beta}^{\gamma} = [\T]_{\beta}^{\gamma}\), then \(\U = \T\) by \cref{2.1.13}.
\end{note}

\begin{defn}\label{2.2.5}
  Let \(\T, \U : \V \to \W\) be arbitrary functions, where \(\V\) and \(\W\) are vector spaces over \(\F\), and let \(a \in \F\).
  We define \(\T + \U : \V \to \W\) by \((\T + \U)(x) = \T(x) + \U(x)\) for all \(x \in \V\), and \(a \T: \V \to \W\) by \((a \T)(x) = a \T(x)\) for all \(x \in \V\).
\end{defn}

\begin{thm}\label{2.7}
  Let \(\V\) and \(\W\) be vector spaces over a field \(\F\), and let \(\T, \U : \V \to \W\) be linear.
  \begin{enumerate}
    \item For all \(a \in \F\), \(a \T + \U\) is linear.
    \item Using the operations of addition and scalar multiplication in \cref{2.2.5}, the collection of all linear transformations from \(\V\) to \(\W\) is a vector space over \(\F\).
  \end{enumerate}
\end{thm}

\begin{proof}[\pf{2.7}(a)]
  Let \(x, y \in \V\) and \(c \in \F\).
  Then
  \begin{align*}
    (a \T + \U)(cx + y) & = a \T(cx + y) + \U(cx + y)            &  & \text{(by \cref{2.2.5})}    \\
                        & = a(\T(cx + y)) + c \U(x) + \U(y)      &  & \text{(by \cref{2.1.2}(b))} \\
                        & = a(c \T(x) + \T(y)) + c \U(x) + \U(y) &  & \text{(by \cref{2.1.2}(b))} \\
                        & = ac \T(x) + c \U(x) + a \T(y) + \U(y) &  & \text{(by \cref{1.2.1})}    \\
                        & = c (a \T + \U)(x) + (a \T + \U)(y).   &  & \text{(by \cref{2.2.5})}
  \end{align*}
  So \(a \T + \U\) is linear.
\end{proof}

\begin{proof}[\pf{2.7}(b)]
  Let \(\ls(\V, \W)\) be the set of all linear transformation from \(\V\) to \(\W\).
  First we show that \ref{vs1}--\ref{vs8} is true.
  Let \(f, g, h \in \ls(\V, \W)\) and let \(a, b \in \F\).
  Now we split into eight cases:
  \begin{description}
    \item[For \ref{vs1}:] We have
      \begin{align*}
        \forall x \in \V, (f + g)(x) & = f(x) + g(x) &  & \text{(by \cref{2.2.5})} \\
                                     & = g(x) + f(x) &  & \text{(by \ref{vs1})}    \\
                                     & = (g + f)(x)  &  & \text{(by \cref{2.2.5})}
      \end{align*}
      and thus \(f + g = g + f\).
    \item[For \ref{vs2}:] We have
      \begin{align*}
        \forall x \in \V, ((f + g) + h)(x) & = (f + g)(x) + h(x)    &  & \text{(by \cref{2.2.5})} \\
                                           & = (f(x) + g(x)) + h(x) &  & \text{(by \cref{2.2.5})} \\
                                           & = f(x) + (g(x) + h(x)) &  & \text{(by \ref{vs2})}    \\
                                           & = f(x) + (g + h)(x)    &  & \text{(by \cref{2.2.5})} \\
                                           & = (f + (g + h))(x)     &  & \text{(by \cref{2.2.5})}
      \end{align*}
      and thus \((f + g) + h = f + (g + h)\).
    \item[For \ref{vs3}:] We have
      \begin{align*}
        \forall x \in \V, (f + \zT)(x) & = f(x) + \zT(x)   &  & \text{(by \cref{2.2.5})} \\
                                       & = f(x) + \zv_{\W} &  & \text{(by \cref{2.1.9})} \\
                                       & = f(x)            &  & \text{(by \ref{vs3})}
      \end{align*}
      and thus \(f + \zT = f\).
    \item[For \ref{vs4}:] We have
      \begin{align*}
        \forall x \in \V, (f + ((-1)f))(x) & = f(x) + ((-1)f)(x) &  & \text{(by \cref{2.2.5})} \\
                                           & = f(x) + (-1)f(x)   &  & \text{(by \cref{2.2.5})} \\
                                           & = \zv_{\W}          &  & \text{(by \ref{vs4})}    \\
                                           & = \zT(x)            &  & \text{(by \cref{2.1.9})}
      \end{align*}
      and thus \(f + (-1)f = \zT\).
    \item[For \ref{vs5}:] We have
      \begin{align*}
        \forall x \in \V, (1f)(x) & = 1f(x) &  & \text{(by \cref{2.2.5})} \\
                                  & = f(x)  &  & \text{(by \ref{vs5})}
      \end{align*}
      and thus \(1f = f\).
    \item[For \ref{vs6}:] We have
      \begin{align*}
        \forall x \in \V, ((ab)f)(x) & = (ab) f(x)   &  & \text{(by \cref{2.2.5})} \\
                                     & = a (bf(x))   &  & \text{(by \ref{vs6})}    \\
                                     & = a ((bf)(x)) &  & \text{(by \cref{2.2.5})} \\
                                     & = (a (bf))(x) &  & \text{(by \cref{2.2.5})}
      \end{align*}
      and thus \((ab)f = a (bf)\).
    \item[For \ref{vs7}:] We have
      \begin{align*}
        \forall x \in \V, (a(f + g))(x) & = a((f + g)(x))     &  & \text{(by \cref{2.2.5})} \\
                                        & = a(f(x) + g(x))    &  & \text{(by \cref{2.2.5})} \\
                                        & = af(x) + ag(x)     &  & \text{(by \ref{vs7})}    \\
                                        & = (af)(x) + (ag)(x) &  & \text{(by \cref{2.2.5})} \\
                                        & = (af + ag)(x)      &  & \text{(by \cref{2.2.5})}
      \end{align*}
      and thus \(a(f + g) = af + ag\).
    \item[For \ref{vs8}:] We have
      \begin{align*}
        \forall x \in \V, ((a + b)f)(x) & = (a + b) f(x)    &  & \text{(by \cref{2.2.5})} \\
                                        & = af(x) + bf(x)   &  & \text{(by \ref{vs8})}    \\
                                        & = af(x) + (bf)(x) &  & \text{(by \cref{2.2.5})} \\
                                        & = (af + bf)(x)    &  & \text{(by \cref{2.2.5})}
      \end{align*}
      and thus \((a + b)f = af + bf\).
  \end{description}
  From the proofs above we see that \ref{vs1}--\ref{vs8} is true.

  By \cref{2.7}(a) and the proofs above we see that
  \[
    \forall \T, \U \in \ls(\V, \W), \T + \U = 1 \T + \U \in \ls(\V, \W)
  \]
  and
  \[
    \forall (c, \T) \in \F \times \ls(\V, \W), c \T = c \T + \zT \in \ls(\V, \W).
  \]
  Thus by \cref{1.2.1} \(\ls(\V, \W)\) is a vector space over \(\F\).
\end{proof}

\begin{defn}\label{2.2.6}
  Let \(\V\) and \(\W\) be vector spaces over \(\F\).
  We denote the vector space of all linear transformations from \(\V\) into \(\W\) by \(\ls(\V, \W)\).
  In the case that \(\V = \W\), we write \(\ls(\V)\) instead of \(\ls(\V, \W)\).
\end{defn}

\begin{thm}\label{2.8}
  Let \(\V\) and \(\W\) be finite-dimensional vector spaces over \(\F\) with ordered bases \(\beta\) and \(\gamma\) over \(\F\), respectively, and let \(\T, \U : \V \to \W\) be linear transformations.
  Then
  \begin{enumerate}
    \item \([\T + \U]_{\beta}^{\gamma} = [\T]_{\beta}^{\gamma} + [\U]_{\beta}^{\gamma}\) and
    \item \([a \T]_{\beta}^{\gamma} = a [\T]_{\beta}^{\gamma}\) for all scalars \(a \in \F\).
  \end{enumerate}
\end{thm}

\begin{proof}[\pf{2.8}(a)]
  Let \(\beta = \set{\seq{v}{1,2,,n}}\) and \(\gamma = \set{\seq{w}{1,2,,m}}\).
  There exist unique scalars \(a_{i j}\) and \(b_{i j}\) (\(1 \leq i \leq m\), \(1 \leq j \leq n\)) such that
  \[
    \T(v_j) = \sum_{i = 1}^m a_{i j} w_i \quad \text{and} \quad \U(v_j) = \sum_{i = 1}^m b_{i j} w_i \quad \text{for } 1 \leq j \leq n.
  \]
  Hence
  \[
    (\T + \U)(v_j) = \sum_{i = 1}^m (a_{i j} + b_{i j}) w_i.
  \]
  Thus
  \[
    ([\T + \U]_{\beta}^{\gamma})_{i j} = a_{i j} + b_{i j} = ([\T]_{\beta}^{\gamma} + [\U]_{\beta}^{\gamma})_{i j}.
  \]
\end{proof}

\begin{proof}[\pf{2.8}(b)]
  Let \(\beta = \set{\seq{v}{1,2,,n}}\).
  There exist unique scalars \(c_{i j}\) (\(1 \leq i \leq m\), \(1 \leq j \leq n\)) such that
  \[
    \T(v_j) = \sum_{i = 1}^m c_{i j} w_i \quad \text{for } 1 \leq j \leq n.
  \]
  Hence
  \[
    (a \T)(v_j) = \sum_{i = 1}^m (a c_{i j}) w_i.
  \]
  Thus
  \[
    ([a \T]_{\beta}^{\gamma})_{i j} = a c_{i j} = a ([\T]_{\beta}^{\gamma})_{i j}.
  \]
\end{proof}

\exercisesection

\setcounter{ex}{7}
\begin{ex}\label{ex:2.2.8}
  Let \(\V\) be an \(n\)-dimensional vector space over \(\F\) with an ordered basis \(\beta\) over \(\F\).
  Define \(\T : \V \to \vs{F}^n\) by \(\T(x) = [x]_{\beta}\).
  Prove that \(\T\) is linear.
\end{ex}

\begin{proof}[\pf{ex:2.2.8}]
  Let \(\beta = \set{\seq{v}{1,2,,n}}\), let \(x, y \in \V\) and let \(c \in \F\).
  Since
  \begin{align*}
             & \exists \seq{a}{1,2,,n}, \seq{b}{1,2,,n} \in \F : \begin{dcases}
                                                                   x = \sum_{i = 1}^n a_i v_i \\
                                                                   y = \sum_{i = 1}^n b_i v_i
                                                                 \end{dcases} &  & \text{(by \cref{1.8})}       \\
    \implies & cx + y = \sum_{i = 1}^n (ca_i + b_i) v_i                         &  & \text{(by \cref{1.2.1})}   \\
    \implies & \T(cx + y) = [cx + y]_{\beta} = \begin{pmatrix}
                                                 ca_1 + b_1 \\
                                                 \vdots     \\
                                                 ca_n + b_n
                                               \end{pmatrix}                  &  & \text{(by \cref{2.2.3})}     \\
             & = c \begin{pmatrix}
                     a_1    \\
                     \vdots \\
                     a_n
                   \end{pmatrix} + \begin{pmatrix}
                                     b_1    \\
                                     \vdots \\
                                     b_n
                                   \end{pmatrix}                                  &  & \text{(by \cref{1.2.9})} \\
             & = c [x]_{\beta} + [y]_{\beta} = c \T(x) + \T(y),                 &  & \text{(by \cref{2.2.3})}
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T\) is linear.
\end{proof}

\begin{ex}\label{ex:2.2.9}
  Let \(\V\) be the vector space of complex numbers \(\C\) over the field \(\R\).
  Define \(\T : \V \to \V\) by \(\T(z) = \overline{z}\), where \(\overline{z}\) is the complex conjugate of \(z\).
  Prove that \(\T\) is linear, and compute \([\T]_{\beta}\), where \(\beta = \set{1, i}\).
  (Recall by \cref{ex:2.1.38} that \(\T\) is not linear if \(\V\) is regarded as a vector space over the field \(\C\).)
\end{ex}

\begin{proof}[\pf{ex:2.2.9}]
  Let \(x, y \in \C\) and let \(c \in \R\).
  Since
  \begin{align*}
    \T(cx + y) & = \overline{cx + y}                              \\
               & = \overline{cx} + \overline{y}                   \\
               & = \overline{c} \cdot \overline{x} + \overline{y} \\
               & = c \overline{x} + \overline{y}                  \\
               & = c \T(x) + \T(y),
  \end{align*}
  by \cref{2.1.2}(b) we know that \(\T\) is linear.
  Since
  \begin{align*}
    \T(1) & = 1 = 1 \cdot 1 + 0 \cdot i,     \\
    \T(i) & = -i = 0 \cdot 1 + (-1) \cdot i,
  \end{align*}
  by \cref{2.2.4} we know that
  \[
    [\T]_{\beta} = \begin{pmatrix}
      1 & 0  \\
      0 & -1
    \end{pmatrix}.
  \]
\end{proof}

\begin{ex}\label{ex:2.2.10}
  Let \(\V\) be a vector space over \(\F\) with the ordered basis \(\beta = \set{\seq{v}{1,2,,n}}\) over \(\F\).
  Define \(v_0 = 0\).
  By \cref{2.6} there exists a linear transformation \(\T : \V \to \V\) such that \(\T(v_j) = v_j + v_{j - 1}\) for \(j = 1, 2, \dots, n\).
  Compute \([\T]_{\beta}\).
\end{ex}

\begin{proof}[\pf{ex:2.2.10}]
  By \cref{2.2.4,ex:1.5.6} we have
  \[
    [\T]_{\beta} = \begin{pmatrix}
      1      & 1      & 0      & \cdots & 0      & 0      & 0      \\
      0      & 1      & 1      & \cdots & 0      & 0      & 0      \\
      0      & 0      & 1      & \cdots & 0      & 0      & 0      \\
      \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
      0      & 0      & 0      & \cdots & 1      & 1      & 0      \\
      0      & 0      & 0      & \cdots & 0      & 1      & 1      \\
      0      & 0      & 0      & \cdots & 0      & 0      & 1
    \end{pmatrix} = \sum_{i = 1}^n E^{i i} + \sum_{i = 2}^n E^{(i - 1) i}.
  \]
\end{proof}

\begin{ex}\label{ex:2.2.11}
  Let \(\V\) be an \(n\)-dimensional vector space over \(\F\), and let \(\T : \V \to \V\) be a linear transformation.
  Suppose that \(\W\) is a \(\T\)-invariant subspace of \(\V\) over \(\F\) (see \cref{2.1.15}) having dimension \(k\).
  Show that there is a basis \(\beta\) for \(\V\) over \(\F\) such that \([\T]_{\beta}\) has the form
  \[
    \begin{pmatrix}
      A   & B \\
      \zm & C
    \end{pmatrix},
  \]
  where \(A\) is a \(k \times k\) matrix and \(\zm\) is the \((n - k) \times k\) zero matrix.
\end{ex}

\begin{proof}[\pf{ex:2.2.11}]
  Let \(\beta_{\W} = \set{\seq{v}{1,2,,k}}\) be a basis for \(\W\) over \(\F\).
  By \cref{1.6.19} we can extend \(\beta_{\W}\) to \(\beta = \set{\seq{v}{1,2,,n}}\) such that \(\beta\) is a basis for \(\V\) over \(\F\).
  Since \(\W\) is \(\T\)-invariant, we know that
  \begin{align*}
             & \T(\W) \subseteq \W                                                                                               &  & \text{(by \cref{2.1.15})} \\
    \implies & \forall v_j \in \beta_{\W}, \T(v_j) \in \W = \spn{\beta_{\W}}                                                     &  & \text{(by \cref{1.6.1})}  \\
    \implies & \forall v_j \in \beta_{\W}, \exists a_{1 j}, a_{2 j}, \dots, a_{k j} \in \F :                                                                    \\
             & \T(v_j) = \sum_{i = 1}^k a_{i j} v_i = \sum_{i = 1}^k a_{i j} v_i + \sum_{i = k + 1}^n 0 v_i                      &  & \text{(by \cref{1.2}(a))} \\
    \implies & \forall v_j \in \beta_{\W}, \exists a_{1 j}, a_{2 j}, \dots, a_{k j} \in \F : [\T(v_j)]_{\beta} = \begin{pmatrix}
                                                                                                                   a_{1 j} \\
                                                                                                                   \vdots  \\
                                                                                                                   a_{k j} \\
                                                                                                                   0       \\
                                                                                                                   \vdots  \\
                                                                                                                   0
                                                                                                                 \end{pmatrix}. &  & \text{(by \cref{2.2.3})}
  \end{align*}
  By setting
  \begin{align*}
    A & = \begin{pmatrix}
            a_{1 1} & \cdots & a_{1 k} \\
            \vdots  & \ddots & \vdots  \\
            a_{k 1} & \cdots & a_{k k}
          \end{pmatrix} \in \ms{k}{k}{\F}                                                                    \\
    B & = \begin{pmatrix}
            ([\T(v_{k + 1})]_{\beta})_1 & \cdots & ([\T(v_n)]_{\beta})_1 \\
            \vdots                      & \ddots & \vdots                \\
            ([\T(v_{k + 1})]_{\beta})_k & \cdots & ([\T(v_n)]_{\beta})_k
          \end{pmatrix} \in \ms{k}{(n - k)}{\F}             \\
    C & = \begin{pmatrix}
            ([\T(v_{k + 1})]_{\beta})_{k + 1} & \cdots & ([\T(v_n)]_{\beta})_{k + 1} \\
            \vdots                            & \ddots & \vdots                      \\
            ([\T(v_{k + 1})]_{\beta})_n       & \cdots & ([\T(v_n)]_{\beta})_n
          \end{pmatrix} \in \ms{(n - k)}{(n - k)}{\F}
  \end{align*}
  we have
  \begin{align*}
    [\T]_{\beta} & = \begin{pmatrix}
                       ([\T(v_1)]_{\beta})_1 & \cdots & ([\T(v_n)]_{\beta})_1   \\
                       \vdots                & \ddots & \vdots                  \\
                       ([\T(v_1)]_{\beta})_n & \cdots & ([\T(v_n)]_{\beta})_{n}
                     \end{pmatrix}                                        &  & \text{(by \cref{2.2.4})}                                        \\
                 & = \begin{pmatrix}
                       a_{1 1} & \cdots & a_{1 k} & ([\T(v_{k + 1})]_{\beta})_1       & \cdots & ([\T(v_n)]_{\beta})_1       \\
                       \vdots  & \ddots & \vdots  & \vdots                            & \ddots & \vdots                      \\
                       a_{k 1} & \cdots & a_{k k} & ([\T(v_{k + 1})]_{\beta})_k       & \cdots & ([\T(v_n)]_{\beta})_k       \\
                       0       & \cdots & 0       & ([\T(v_{k + 1})]_{\beta})_{k + 1} & \cdots & ([\T(v_n)]_{\beta})_{k + 1} \\
                       \vdots  & \ddots & \vdots  & \vdots                            & \ddots & \vdots                      \\
                       0       & \cdots & 0       & ([\T(v_{k + 1})]_{\beta})_{n}     & \cdots & ([\T(v_n)]_{\beta})_{n}
                     \end{pmatrix} \\
                 & = \begin{pmatrix}
                       A   & B \\
                       \zm & C
                     \end{pmatrix}.
  \end{align*}
\end{proof}

\begin{ex}\label{ex:2.2.12}
  Let \(\V\) be a finite-dimensional vector space over \(\F\) and \(\T\) be the projection on \(\W\) along \(\W'\), where \(\W\) and \(\W'\) are subspaces of \(\V\) over \(\F\).
  (See \cref{2.1.14}.)
  Find an ordered basis \(\beta\) for \(\V\) over \(\F\) such that \([\T]_{\beta}\) is a diagonal matrix.
\end{ex}

\begin{proof}[\pf{ex:2.2.12}]
  Let \(\beta_{\W} = \set{\seq{v}{1,2,,k}}\) be a basis for \(\W\) over \(\F\).
  By \cref{1.6.19} we can extend \(\beta_{\W}\) to \(\beta = \set{\seq{v}{1,2,,n}}\) such that \(\beta\) is a basis for \(\V\) over \(\F\).
  Since
  \begin{align*}
             & \begin{dcases}
                 \forall v_j \in \beta_{\W}, v_j = v_j + \zv \in \W + \W' \\
                 \forall v_j \in \beta \setminus \beta_{\W}, v_j = \zv + v_j \in \W + \W'
               \end{dcases}                         &  & \text{(by \cref{1.3.10})}                         \\
    \implies & \begin{dcases}
                 \forall v_j \in \beta_{\W}, \T(v_j) = v_j \\
                 \forall v_j \in \beta \setminus \beta_{\W}, \T(v_j) = \zv
               \end{dcases}                                        &  & \text{(by \cref{2.1.14})}              \\
    \implies & \begin{dcases}
                 \forall v_j \in \beta_{\W}, [\T(v_j)]_{\beta} = e_j \in \vs{F}^n \\
                 \forall v_j \in \beta \setminus \beta_{\W}, [\T(v_j)]_{\beta} = \zv \in \vs{F}^n
               \end{dcases} &  & \text{(by \cref{2.2.2})} \\
    \implies & [\T]_{\beta} = \begin{pmatrix}
                                e_1 & \cdots & e_k & \zv & \cdots & \zv
                              \end{pmatrix}                                          \\
             & = \begin{pmatrix}
                   1      & 0      & \cdots & 0      & 0      & \cdots & 0      \\
                   0      & 1      & \cdots & 0      & 0      & \cdots & 0      \\
                   \vdots & \vdots & \ddots & \vdots & 0      & \cdots & 0      \\
                   0      & 0      & \cdots & 1      & 0      & \cdots & 0      \\
                   0      & 0      & \cdots & 0      & 0      & \cdots & 0      \\
                   \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
                   0      & 0      & \cdots & 0      & 0      & \cdots & 0
                 \end{pmatrix},
  \end{align*}
  by \cref{1.3.8} we know that \([\T]_{\beta}\) is a diagonal matrix.
\end{proof}
